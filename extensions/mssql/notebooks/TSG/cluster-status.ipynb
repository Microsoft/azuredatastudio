{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "# Cluster Status Notebook\r\nThis notebook allows you to see the status of the controller, master instance, and pools in your SQL Server big data cluster.\r\n\r\n## Big data cluster Status \r\nStarting with SQL Server 2019 preview, SQL Server big data clusters allow you to deploy scalable clusters of SQL Server, Spark, and HDFS containers running on Kubernetes. To learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "import os, getpass\r\n# Login in to your big data cluster \r\n\r\ncluster_name = input('Please provide your cluster Name: ')\r\ncontroller_username = 'admin'\r\nprint('Please provide password: ')\r\ncontroller_password = getpass.getpass()\r\nprint('***********')\r\ncmd = f'!mssqlctl login -n {cluster_name}'\r\nprint(\"Start \" + cmd)\r\nos.environ['CONTROLLER_USERNAME'] = controller_username\r\nos.environ['CONTROLLER_PASSWORD'] = controller_password\r\nos.environ['ACCEPT_EULA'] = 'yes'\r\n# Display status of big data cluster\r\n!mssqlctl login -n {cluster_name}",
            "metadata": {},
            "outputs": [],
            "execution_count": 6
        },
        {
            "cell_type": "code",
            "source": "# Display endpoints of the cluster\r\n!mssqlctl bdc endpoint list",
            "metadata": {},
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": "# Display status of big data cluster\r\n!mssqlctl bdc status show -o table",
            "metadata": {},
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "markdown",
            "source": "## Controller status\r\nThe controller hosts the core logic for deploying and managing a big data cluster. It takes care of all interactions with Kubernetes, SQL server instances that are part of the cluster and other components like like HDFS and Spark. \r\n\r\nTo learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/concept-controller?view=sql-server-ver15)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of controller\r\n!mssqlctl bdc control status show -o table",
            "metadata": {},
            "outputs": [],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": "## Master Instance status\r\nThe master instance is a SQL Server instance running in a SQL Server big data cluster control plane.\r\n\r\nTo learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/concept-master-instance?view=sqlallproducts-allversions)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of master instance\r\n!mssqlctl bdc master-pool status show -o table",
            "metadata": {},
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": "## Compute Pool status\r\nCompute pools provide scale-out computational resources for a big data cluster.\r\n\r\nTo learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/concept-compute-pool?view=sqlallproducts-allversions)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of compute pool\r\n!mssqlctl bdc compute-pool status show -o table",
            "metadata": {},
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": "## Storage Pool status\r\nStorage pool are responsible for:\r\n- Data ingestion through Spark.\r\n- Data storage in HDFS (Parquet format). HDFS also provides data persistency, as HDFS data is spread across all the storage nodes in the SQL big data cluster.\r\n- Data access through HDFS And SQL Server endpoints.\r\n\r\nTo learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/concept-storage-pool?view=sqlallproducts-allversions)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of storage pools\r\n!mssqlctl bdc storage-pool status show -o table",
            "metadata": {},
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": "## Data Pool status\r\nSQL data pool instances provide persistent SQL Server storage for the cluster. A data pool is used to ingest data from SQL queries or Spark jobs. \r\n\r\nTo learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/concept-data-pool?view=sqlallproducts-allversions)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of data pools\r\n!mssqlctl bdc data-pool status show -o table",
            "metadata": {},
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": "## Spark Pool status\r\n",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of spark pool\r\n!mssqlctl bdc spark-pool status show -o table",
            "metadata": {},
            "outputs": [],
            "execution_count": 6
        }
    ]
}