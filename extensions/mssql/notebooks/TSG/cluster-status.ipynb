{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "# Cluster Status Notebook\nThis notebook allows you to see the status of the controller, master instance, and pools in your SQL Server big data cluster.",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "import sys, platform\r\n\r\nif platform.system()==\"Windows\":\r\n    user = ' --user'\r\nelse:\r\n    user = ''\r\n    \r\ncmd = f'{sys.executable} -m pip uninstall --yes mssqlctl-cli-storage'\r\ncmdOutput = !{cmd}\r\ncmd = f'{sys.executable} -m pip uninstall -r http://helsinki/browse/packages/python/aris-p-release-candidate-gb/mssqlctl/requirements.txt --yes'\r\n\r\ncmdOutput = !{cmd}\r\ncmdOutput = ''.join(cmdOutput)\r\nif 'is not installed' in cmdOutput or 'Successfully uninstalled mssqlctl' in cmdOutput:\r\n    print(\"Uninstalling mssqlctl successful: \" + cmd)\r\nelse:\r\n    raise SystemExit(f'Uninstall of mssqlctl failed:\\n\\n\\t{cmd}\\n\\nreturned non-zero exit code: ' + ''.join(cmdOutput) + '.\\n')\r\n\r\ncmd = f'{sys.executable} -m pip install -r http://helsinki/browse/packages/python/aris-p-release-candidate-gb/mssqlctl/requirements.txt{user} --trusted-host helsinki'\r\nprint(\"Installing the latest version of mssqlctl: \" + cmd)\r\ncmdOutput = !{cmd}\r\ncmdOutput = ''.join(cmdOutput)\r\nif 'Requirement already satisfied' in cmdOutput or 'Successfully installed mssqlctl' in cmdOutput:\r\n    print(f'\\nSUCCESS: Upgraded the mssqlctl to the latest version')\r\nelse:\r\n    raise SystemExit(f'Installation of mssqlctl failed:\\n\\n\\t{cmd}\\n\\nreturned non-zero exit code: ' + ''.join(cmdOutput) + '.\\n')\r\n\r\n#install pandas\r\ncmd = f'{sys.executable} -m pip show pandas'\r\ncmdOutput = !{cmd}\r\nif len(cmdOutput) > 0 and '0.24' in cmdOutput[1]:\r\n    print('Pandas required version is already installed!')\r\nelse:\r\n    pandasVersion = 'pandas==0.24.2'\r\n    cmd = f'{sys.executable} -m pip install {pandasVersion}'\r\n    cmdOutput = !{cmd}\r\n    print(f'\\nSuccess: Upgraded pandas.')\r\n",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Uninstalling mssqlctl successful: /Users/madhurikoripalli/azuredatastudio-python/0.0.1/bin/python3.6 -m pip uninstall -r http://helsinki/browse/packages/python/aris-p-release-candidate-gb/mssqlctl/requirements.txt --yes\nInstalling the latest version of mssqlctl: /Users/madhurikoripalli/azuredatastudio-python/0.0.1/bin/python3.6 -m pip install -r http://helsinki/browse/packages/python/aris-p-release-candidate-gb/mssqlctl/requirements.txt --trusted-host helsinki\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "\nSUCCESS: Upgraded the mssqlctl to the latest version\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "Pandas required version is already installed!\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 15
        },
        {
            "cell_type": "code",
            "source": "import os, getpass, sys, json\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import *\n\n# Check if mssqlctl is installed\ncmd = f'{sys.executable} -m mssqlctl --version'\nmssqlctl_version = !{cmd}\n\nif 'mssqlctl: command not found' in mssqlctl_version[0]:\n        raise SystemExit(f'mssqlctl is Required, Please install the latest version before proceeding. Thanks! ' + '.\\n')\n\n # set display colwidth to avoid truncation of result data \npd.set_option('display.max_colwidth', -1)\n# Prompt user inputs:\ncluster_name = input('Please provide your Cluster Name: ')\nif cluster_name == \"\":\n    raise SystemExit(f'Cluster Name is required!' + '\\n')\ncontroller_username = input('Please provide your Controller Username for login: ')\nif controller_username == \"\":\n    raise SystemExit(f'Controller Username is required!' + '\\n')\ncontroller_password = getpass.getpass(prompt='Controller Password: ')\nif controller_password == \"\":\n    raise SystemExit(f'Password is required!' + '\\n')\nelse:\n    print('***********')\n\n# Login in to your big data cluster \ncmd = f'mssqlctl login -n {cluster_name} -u {controller_username} -a yes'\nprint(\"Start \" + cmd)\nos.environ['CONTROLLER_USERNAME'] = controller_username\nos.environ['CONTROLLER_PASSWORD'] = controller_password\nos.environ['ACCEPT_EULA'] = 'yes'\n\nloginResult = !{cmd}\nif 'ERROR: Please check your kube config or specify the correct controller endpoint with: --controller-endpoint https://<ip>:<port>.' in loginResult[0] or 'ERROR' in loginResult[0]:\n    controller_ip = input('Please provide your Controller endpoint: ')\n    if controller_ip == \"\":\n        raise SystemExit(f'Controller IP is required!' + '\\n')\n    else:\n        cmd = f'mssqlctl login -n {cluster_name} -e {controller_ip} -u {controller_username} -a yes'\n        loginResult = !{cmd}\nprint(loginResult)\n# mssqlctl login -n test -e  https://10.127.22.122:30080 -u controlleradmin -a yes    \n# mssqlctl login -n june14-bdc -u admin -a yes\n# User `admin` logged in successfully to `https://13.68.131.229:30080",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "text": "***********\nStart mssqlctl login -n june14-bdc -u admin -a yes\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "['User `admin` logged in successfully to `https://13.68.131.229:30080`']\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 11
        },
        {
            "cell_type": "code",
            "source": "# Display status of big data cluster\ndef formatColumnNames(column):\n    return ' '.join(word[0].upper() + word[1:] for word in column.split())\n\ndef show_results(input):\n    input = ''.join(input)\n    results = json.loads(input)\n    df = pd.DataFrame(results)\n    df.columns = [formatColumnNames(n) for n in results[0].keys()]\n    mydata = HTML(df.to_html(render_links=True))\n    display(mydata)\n\nresults  = !mssqlctl bdc status show\nstrRes = ''.join(results)\njsonRes = json.loads(strRes)\ndtypes = '{'\nspark = [x for x in jsonRes if x['kind'] == 'Spark']\nif spark:\n    spark_exists = True\nelse:\n    spark_exists = False\nshow_results(results)",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>",
                        "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Kind</th>\n      <th>Name</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BDC</td>\n      <td>june14-bdc</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Control</td>\n      <td>default</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Master</td>\n      <td>default</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Compute</td>\n      <td>default</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Data</td>\n      <td>default</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Storage</td>\n      <td>default</td>\n      <td>Ready</td>\n    </tr>\n  </tbody>\n</table>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "markdown",
            "source": "## Controller status\nThe controller hosts the core logic for deploying and managing a big data cluster. It takes care of all interactions with Kubernetes, SQL server instances that are part of the cluster and other components like like HDFS and Spark. \n\nTo learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/concept-controller?view=sql-server-ver15)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of controller\nresults = !mssqlctl bdc control status show\nshow_results(results)",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>",
                        "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Kind</th>\n      <th>LogsUrl</th>\n      <th>Name</th>\n      <th>NodeMetricsUrl</th>\n      <th>SqlMetricsUrl</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DaemonSet</td>\n      <td>-</td>\n      <td>metricsdc</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/metricsdc-5bdk8/nodemetrics/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/metricsdc-5bdk8/nodemetrics/ui</a></td>\n      <td>-</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ReplicaSet</td>\n      <td>-</td>\n      <td>metricsui</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/metricsui-sbvdp/nodemetrics/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/metricsui-sbvdp/nodemetrics/ui</a></td>\n      <td>-</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>StatefulSet</td>\n      <td>-</td>\n      <td>metricsdb</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/metricsdb-0/nodemetrics/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/metricsdb-0/nodemetrics/ui</a></td>\n      <td>-</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ReplicaSet</td>\n      <td>-</td>\n      <td>logsui</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/logsui-6kcnj/nodemetrics/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/logsui-6kcnj/nodemetrics/ui</a></td>\n      <td>-</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>StatefulSet</td>\n      <td>-</td>\n      <td>logsdb</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/logsdb-0/nodemetrics/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/logsdb-0/nodemetrics/ui</a></td>\n      <td>-</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>StatefulSet</td>\n      <td>-</td>\n      <td>nmnode-0</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/nmnode-0-0/nodemetrics/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/nmnode-0-0/nodemetrics/ui</a></td>\n      <td>-</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>StatefulSet</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/gateway-0/logs/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/gateway-0/logs/ui</a></td>\n      <td>gateway</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/gateway-0/nodemetrics/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/gateway-0/nodemetrics/ui</a></td>\n      <td>-</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ReplicaSet</td>\n      <td>-</td>\n      <td>mgmtproxy</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/mgmtproxy-rntml/nodemetrics/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/mgmtproxy-rntml/nodemetrics/ui</a></td>\n      <td>-</td>\n      <td>Ready</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ReplicaSet</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/control-l7bkg/logs/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/control-l7bkg/logs/ui</a></td>\n      <td>control</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/control-l7bkg/nodemetrics/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/control-l7bkg/nodemetrics/ui</a></td>\n      <td>-</td>\n      <td>Running</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>StatefulSet</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/controldb-0/logs/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/controldb-0/logs/ui</a></td>\n      <td>controldb</td>\n      <td><a href=\"https://13.68.131.229:30080/clusters/june14-bdc/pods/controldb-0/nodemetrics/ui\" target=\"_blank\">https://13.68.131.229:30080/clusters/june14-bdc/pods/controldb-0/nodemetrics/ui</a></td>\n      <td>-</td>\n      <td>Running</td>\n    </tr>\n  </tbody>\n</table>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "execution_count": 13
        },
        {
            "cell_type": "markdown",
            "source": "## Master Instance status\nThe master instance is a SQL Server instance running in a SQL Server big data cluster control plane.\n\nTo learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/concept-master-instance?view=sqlallproducts-allversions)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of master instance\nresults = !mssqlctl bdc pool status show -k master -n default\nshow_results(results)",
            "metadata": {},
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": "## Compute Pool status\nCompute pools provide scale-out computational resources for a big data cluster.\n\nTo learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/concept-compute-pool?view=sqlallproducts-allversions)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of compute pool\nresults = !mssqlctl bdc pool status show -k compute -n default\nshow_results(results)",
            "metadata": {},
            "outputs": [],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": "## Storage Pool status\nStorage pool are responsible for:\n- Data ingestion through Spark.\n- Data storage in HDFS (Parquet format). HDFS also provides data persistency, as HDFS data is spread across all the storage nodes in the SQL big data cluster.\n- Data access through HDFS And SQL Server endpoints.\n\nTo learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/concept-storage-pool?view=sqlallproducts-allversions)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of storage pools\nresults = !mssqlctl bdc pool status show -k storage -n default\nshow_results(results)",
            "metadata": {},
            "outputs": [],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": "## Data Pool status\nSQL data pool instances provide persistent SQL Server storage for the cluster. A data pool is used to ingest data from SQL queries or Spark jobs. \n\nTo learn more, [read here.](https://docs.microsoft.com/sql/big-data-cluster/concept-data-pool?view=sqlallproducts-allversions)",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of data pools\nresults = !mssqlctl bdc pool status show -k data -n default\nshow_results(results)",
            "metadata": {},
            "outputs": [],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": "## Spark Pool status\n",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Display status of spark pool\nif spark_exists:\n    results = !mssqlctl bdc pool status show -k spark -n default\n    show_results(results)\nelse:\n    print('No spark pool.')",
            "metadata": {},
            "outputs": [],
            "execution_count": 9
        }
    ]
}