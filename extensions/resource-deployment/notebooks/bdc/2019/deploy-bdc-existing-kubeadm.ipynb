{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "![Microsoft](https://raw.githubusercontent.com/microsoft/azuredatastudio/master/src/sql/media/microsoft-small-logo.png)\n",
                " \n",
                "## Deploy SQL Server 2019 Big Data Cluster on an existing cluster deployed using kubeadm\n",
                " \n",
                "This notebook walks through the process of deploying a <a href=\"https://docs.microsoft.com/sql/big-data-cluster/big-data-cluster-overview?view=sqlallproducts-allversions\">SQL Server 2019 Big Data Cluster</a> on an existing kubeadm cluster.\n",
                " \n",
                "* Follow the instructions in the **Prerequisites** cell to install the tools if not already installed.\n",
                "* Make sure you have the target cluster set as the current context in your kubectl config file.\n",
                "        The config file would typically be under C:\\Users\\(userid)\\.kube on Windows, and under ~/.kube/ for macOS and Linux for a default installation.\n",
                "        In the kubectl config file, look for \"current-context\" and ensure it is set to the AKS cluster that the SQL Server 2019 Big Data Cluster will be deployed to.\n",
                "* The **Required information** cell will prompt you for password that will be used to access the cluster controller, SQL Server, and Knox.\n",
                "* The values in the **Default settings** cell can be changed as appropriate.\n",
                "\n",
                "<span style=\"color:red\"><font size=\"3\">Please press the \"Run Cells\" button to run the notebook</font></span>"
            ],
            "metadata": {
                "azdata_cell_guid": "23954d96-3932-4a8e-ab73-da605f99b1a4"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Prerequisites** \n",
                "Ensure the following tools are installed and added to PATH before proceeding.\n",
                " \n",
                "|Tools|Description|Installation|\n",
                "|---|---|---|\n",
                "|kubectl | Command-line tool for monitoring the underlying Kuberentes cluster | [Installation](https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-binary-using-native-package-management) |\n",
                "|azdata | Command-line tool for installing and managing a Big Data Cluster |[Installation](https://docs.microsoft.com/en-us/sql/big-data-cluster/deploy-install-azdata?view=sqlallproducts-allversions) |"
            ],
            "metadata": {
                "azdata_cell_guid": "1d7f4c6a-0cb8-4ecc-81c8-544712253a3f"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Check dependencies**"
            ],
            "metadata": {
                "azdata_cell_guid": "a31f9894-903f-4e19-a5a8-6fd888ff013b"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas,sys,os,json,html,getpass,time\r\n",
                "pandas_version = pandas.__version__.split('.')\r\n",
                "pandas_major = int(pandas_version[0])\r\n",
                "pandas_minor = int(pandas_version[1])\r\n",
                "pandas_patch = int(pandas_version[2])\r\n",
                "if not (pandas_major > 0 or (pandas_major == 0 and pandas_minor > 24) or (pandas_major == 0 and pandas_minor == 24 and pandas_patch >= 2)):\r\n",
                "    sys.exit('Please upgrade the Notebook dependency before you can proceed, you can do it by running the \"Reinstall Notebook dependencies\" command in command palette (View menu -> Command Paletteâ€¦).')\r\n",
                "\r\n",
                "def run_command():\r\n",
                "    print(\"Executing: \" + cmd)\r\n",
                "    !{cmd}\r\n",
                "    if _exit_code != 0:\r\n",
                "        sys.exit(f'Command execution failed with exit code: {str(_exit_code)}.\\n\\t{cmd}\\n')\r\n",
                "    print(f'Successfully executed: {cmd}')\r\n",
                "\r\n",
                "cmd = 'kubectl version --client=true'\r\n",
                "run_command()\r\n",
                "cmd = 'azdata --version'\r\n",
                "run_command()"
            ],
            "metadata": {
                "azdata_cell_guid": "26fa8bc4-4b8e-4c31-ae11-50484821cea8"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Required information**"
            ],
            "metadata": {
                "azdata_cell_guid": "7b383b0d-5687-45b3-a16f-ba3b170c796e"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "env_var_flag = \"AZDATA_NB_VAR_BDC_ADMIN_PASSWORD\" in os.environ\n",
                "if env_var_flag:\n",
                "    mssql_password = os.environ[\"AZDATA_NB_VAR_BDC_ADMIN_PASSWORD\"]\n",
                "    mssql_controller_data_storage_class = os.environ[\"AZDATA_NB_VAR_BDC_CONTROLLER_DATA_STORAGE_CLASS\"]\n",
                "    mssql_controller_data_size = os.environ[\"AZDATA_NB_VAR_BDC_CONTROLLER_DATA_STORAGE_SIZE\"]\n",
                "    mssql_controller_logs_storage_class = os.environ[\"AZDATA_NB_VAR_BDC_CONTROLLER_LOGS_STORAGE_CLASS\"]\n",
                "    mssql_controller_logs_size = os.environ[\"AZDATA_NB_VAR_BDC_CONTROLLER_LOGS_STORAGE_SIZE\"]\n",
                "    mssql_datapool_data_storage_class = os.environ[\"AZDATA_NB_VAR_BDC_DATA_DATA_STORAGE_CLASS\"]\n",
                "    mssql_datapool_data_size = os.environ[\"AZDATA_NB_VAR_BDC_DATA_DATA_STORAGE_SIZE\"]\n",
                "    mssql_datapool_logs_storage_class = os.environ[\"AZDATA_NB_VAR_BDC_DATA_LOGS_STORAGE_CLASS\"]\n",
                "    mssql_datapool_logs_size = os.environ[\"AZDATA_NB_VAR_BDC_DATA_LOGS_STORAGE_SIZE\"]\n",
                "    mssql_hdfs_data_storage_class = os.environ[\"AZDATA_NB_VAR_BDC_HDFS_DATA_STORAGE_CLASS\"]\n",
                "    mssql_hdfs_data_size = os.environ[\"AZDATA_NB_VAR_BDC_HDFS_DATA_STORAGE_SIZE\"]\n",
                "    mssql_hdfs_logs_storage_class = os.environ[\"AZDATA_NB_VAR_BDC_HDFS_LOGS_STORAGE_CLASS\"]\n",
                "    mssql_hdfs_logs_size = os.environ[\"AZDATA_NB_VAR_BDC_HDFS_LOGS_STORAGE_SIZE\"]\n",
                "    mssql_sql_data_storage_class = os.environ[\"AZDATA_NB_VAR_BDC_SQL_DATA_STORAGE_CLASS\"]\n",
                "    mssql_sql_data_size = os.environ[\"AZDATA_NB_VAR_BDC_SQL_DATA_STORAGE_SIZE\"]\n",
                "    mssql_sql_logs_storage_class = os.environ[\"AZDATA_NB_VAR_BDC_SQL_LOGS_STORAGE_CLASS\"]\n",
                "    mssql_sql_logs_size = os.environ[\"AZDATA_NB_VAR_BDC_SQL_LOGS_STORAGE_SIZE\"]\n",
                "else: \n",
                "    mssql_password = getpass.getpass(prompt = 'SQL Server 2019 Big Data Cluster controller password')\n",
                "    if mssql_password == \"\":\n",
                "        sys.exit(f'Password is required.')\n",
                "    confirm_password = getpass.getpass(prompt = 'Confirm password')\n",
                "    if mssql_password != confirm_password:\n",
                "        sys.exit(f'Passwords do not match.')\n",
                "    mssql_controller_data_storage_class = input('Storage class name')\n",
                "    mssql_controller_data_size = input('Capacity for data in GB, default is 15GB')\n",
                "    if mssql_controller_data_size == \"\":\n",
                "        mssql_controller_data_size = \"15\"\n",
                "    mssql_controller_logs_size = input('Capacity for logs in GB, default is 10GB')\n",
                "    if mssql_controller_logs_size == \"\":\n",
                "        mssql_controller_logs_size = \"10\"\n",
                "    mssql_controller_logs_storage_class = mssql_controller_data_storage_class\n",
                "\n",
                "print('You can also use the same password to access Knox and SQL Server.')"
            ],
            "metadata": {
                "azdata_cell_guid": "b5970f2b-cf13-41af-b0a2-5133d840325e"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Default settings**"
            ],
            "metadata": {
                "azdata_cell_guid": "1d28aac5-955d-4b15-8b9c-8d6ec2b588fe"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "if env_var_flag:\n",
                "    mssql_cluster_name = os.environ[\"AZDATA_NB_VAR_BDC_CLUSTER_NAME\"]\n",
                "    mssql_controller_username = os.environ[\"AZDATA_NB_VAR_BDC_CONTROLLER_USERNAME\"]\n",
                "    mssql_source_profile = os.environ[\"AZDATA_NB_VAR_BDC_DEPLOYMENT_PROFILE\"]\n",
                "    mssql_kube_config_path = os.environ[\"AZDATA_NB_VAR_BDC_KUBECONFIG_PATH\"]\n",
                "    mssql_cluster_context = os.environ[\"AZDATA_NB_VAR_BDC_CLUSTER_CONTEXT\"]\n",
                "    mssql_sqlserver_scale = os.environ[\"AZDATA_NB_VAR_BDC_MASTERSQL_SCALE\"]\n",
                "    mssql_compute_scale = os.environ[\"AZDATA_NB_VAR_BDC_COMPUTEPOOL_SCALE\"]\n",
                "    mssql_data_scale = os.environ[\"AZDATA_NB_VAR_BDC_DATAPOOL_SCALE\"]\n",
                "    mssql_hdfs_scale = os.environ[\"AZDATA_NB_VAR_BDC_HDFSPOOL_SCALE\"]\n",
                "    mssql_spark_scale = os.environ[\"AZDATA_NB_VAR_BDC_SPARKPOOL_SCALE\"]\n",
                "    mssql_name_node_scale = os.environ[\"AZDATA_NB_VAR_BDC_NAMENODE_SCALE\"]\n",
                "    mssql_include_spark = os.environ[\"AZDATA_NB_VAR_BDC_INCLUDESPARK\"]\n",
                "    mssql_controller_port = os.environ[\"AZDATA_NB_VAR_BDC_CONTROLLER_PORT\"]\n",
                "    mssql_sqlserver_port = os.environ[\"AZDATA_NB_VAR_BDC_SQL_PORT\"]\n",
                "    mssql_gateway_port = os.environ[\"AZDATA_NB_VAR_BDC_GATEWAY_PORT\"]\n",
                "    mssql_readable_secondary_port = os.environ[\"AZDATA_NB_VAR_BDC_READABLE_SECONDARY_PORT\"]\n",
                "    mssql_hadr_enabled = os.environ[\"AZDATA_NB_VAR_BDC_ENABLE_HADR\"] == \"true\"\n",
                "    os.environ[\"KUBECONFIG\"] = mssql_kube_config_path\n",
                "else:\n",
                "    mssql_source_profile = 'kubeadm-dev-test'\n",
                "    mssql_cluster_name = 'mssql-cluster'\n",
                "    mssql_controller_username = 'admin'\n",
                "mssql_target_profile = 'mssql-bdc-configuration'\n",
                "print(f'SQL Server Big Data Cluster name: {mssql_cluster_name}')\n",
                "print(f'SQL Server Big Data Cluster controller username: {mssql_controller_username}')\n",
                "print(f'Deployment source profile: {mssql_source_profile}')\n",
                "print(f'Deployment profile: {mssql_target_profile}')\n",
                "print(f'Data storage class name: {mssql_controller_data_storage_class}')\n",
                "print(f'Logs storage class name: {mssql_controller_logs_storage_class}')\n",
                "print(f'Data storage size(GB): {mssql_controller_data_size}')\n",
                "print(f'Logs storage size(GB): {mssql_controller_logs_size}')\n",
                "if(env_var_flag):\n",
                "    print(f'kube config path: {mssql_kube_config_path}')\n",
                "    print(f'Cluster context: {mssql_cluster_context}')\n",
                "    print(f'Master SQL Server scale: {mssql_sqlserver_scale}')\n",
                "    print(f'Compute pool scale: {mssql_compute_scale}')\n",
                "    print(f'HDFS pool scale: {mssql_hdfs_scale}')\n",
                "    print(f'Include Spark in HDFS pool: {mssql_include_spark}')\n",
                "    print(f'Data pool scale: {mssql_data_scale}')\n",
                "    print(f'Spark pool scale: {mssql_spark_scale}')\n",
                "    print(f'HDFS name node scale: {mssql_name_node_scale}')\n",
                "    print(f'Controller port: {mssql_controller_port}')\n",
                "    print(f'SQL Server port: {mssql_sqlserver_port}')\n",
                "    print(f'Gateway port: {mssql_gateway_port}')\n",
                "    print(f'Readable secondary port: {mssql_readable_secondary_port}')\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "5502295c-cc80-4a1c-82b0-4228a4bfae21"
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Set and show current context**"
            ],
            "metadata": {
                "azdata_cell_guid": "6456bd0c-5b64-4d76-be59-e3a5b32697f5"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "if mssql_cluster_context is not None:\n",
                "    cmd = f'kubectl config use-context {mssql_cluster_context}'\n",
                "    run_command()\n",
                "cmd = 'kubectl config current-context'\n",
                "run_command()"
            ],
            "metadata": {
                "azdata_cell_guid": "a38f8b3a-f93a-484c-b9e2-4eba3ed99cc2"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Create a deployment configuration file**"
            ],
            "metadata": {
                "azdata_cell_guid": "6d78da36-6af5-4309-baad-bc81bb2cdb7f"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "os.environ[\"ACCEPT_EULA\"] = 'yes'\n",
                "cmd = f'azdata bdc config init --source {mssql_source_profile} --target {mssql_target_profile} --force'\n",
                "run_command()\n",
                "cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j metadata.name={mssql_cluster_name}'\n",
                "run_command()\n",
                "if mssql_sqlserver_scale is not None:\n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j $.spec.resources.master.spec.replicas={mssql_sqlserver_scale}'\n",
                "    run_command()\n",
                "if mssql_name_node_scale is not None:\n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j $.spec.resources.nmnode-0.spec.replicas={mssql_name_node_scale}'\n",
                "    run_command()\n",
                "if mssql_compute_scale is not None: \n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j $.spec.resources.compute-0.spec.replicas={mssql_compute_scale}'\n",
                "    run_command()\n",
                "if mssql_data_scale is not None: \n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j $.spec.resources.data-0.spec.replicas={mssql_data_scale}'\n",
                "    run_command()\n",
                "if mssql_hdfs_scale is not None: \n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j $.spec.resources.storage-0.spec.replicas={mssql_hdfs_scale}'\n",
                "    run_command()\n",
                "if mssql_include_spark is not None: \n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j $.spec.resources.storage-0.spec.settings.spark.includeSpark={mssql_include_spark}'\n",
                "    run_command()\n",
                "if mssql_spark_scale is not None: \n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j $.spec.resources.sparkhead.spec.replicas={mssql_spark_scale}'\n",
                "    run_command()\n",
                "if mssql_controller_port is not None: \n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/control.json -j \"$.spec.endpoints[?(@.name==\"\"Controller\"\")].port={mssql_controller_port}\"'\n",
                "    run_command()\n",
                "if mssql_sqlserver_port is not None: \n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j \"$.spec.resources.master.spec.endpoints[?(@.name==\"\"Master\"\")].port={mssql_sqlserver_port}\"'\n",
                "    run_command()\n",
                "if mssql_gateway_port is not None: \n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j \"$.spec.resources.gateway.spec.endpoints[?(@.name==\"\"Knox\"\")].port={mssql_gateway_port}\"'\n",
                "    run_command()\n",
                "if mssql_readable_secondary_port is not None and mssql_readable_secondary_port != \"\": \n",
                "    cmd = f'azdata bdc config replace -c {mssql_target_profile}/bdc.json -j \"$.spec.resources.master.spec.endpoints[?(@.name==\"\"MasterSecondary\"\")].port={mssql_readable_secondary_port}\"'\n",
                "    run_command()\n",
                "cmd = f'azdata bdc config replace -c {mssql_target_profile}/control.json -j $.spec.storage.data.className={mssql_controller_data_storage_class}'\n",
                "run_command()\n",
                "cmd = f'azdata bdc config replace -c {mssql_target_profile}/control.json -j $.spec.storage.data.size={mssql_controller_data_size}Gi'\n",
                "run_command()\n",
                "cmd = f'azdata bdc config replace -c {mssql_target_profile}/control.json -j $.spec.storage.logs.className={mssql_controller_logs_storage_class}'\n",
                "run_command()\n",
                "cmd = f'azdata bdc config replace -c {mssql_target_profile}/control.json -j $.spec.storage.logs.size={mssql_controller_logs_size}Gi'\n",
                "run_command()\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "3110ab23-ecfc-4e36-a1c5-28536b7edebf"
            },
            "outputs": [],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Create SQL Server 2019 Big Data Cluster**"
            ],
            "metadata": {
                "azdata_cell_guid": "7d56d262-8cd5-49e4-b745-332c6e7a3cb2"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print (f'Creating SQL Server 2019 Big Data Cluster: {mssql_cluster_name} using configuration {mssql_target_profile}')\n",
                "os.environ[\"CONTROLLER_USERNAME\"] = mssql_controller_username\n",
                "os.environ[\"CONTROLLER_PASSWORD\"] = mssql_password\n",
                "os.environ[\"MSSQL_SA_PASSWORD\"] = mssql_password\n",
                "os.environ[\"KNOX_PASSWORD\"] = mssql_password\n",
                "cmd = f'azdata bdc create -c {mssql_target_profile}'\n",
                "run_command()"
            ],
            "metadata": {
                "azdata_cell_guid": "0a743e88-e7d0-4b41-b8a3-e43985d15f2b"
            },
            "outputs": [],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Login to SQL Server 2019 Big Data Cluster**"
            ],
            "metadata": {
                "azdata_cell_guid": "7929fd90-324d-482a-a101-ae29cb183691"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "cmd = f'azdata login --cluster-name {mssql_cluster_name}'\n",
                "run_command()"
            ],
            "metadata": {
                "azdata_cell_guid": "3a49909b-e09e-4e62-a825-c39de2cffc94"
            },
            "outputs": [],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Show SQL Server 2019 Big Data Cluster endpoints**"
            ],
            "metadata": {
                "azdata_cell_guid": "038e801a-a393-4f8d-8e2d-97bc3b740b0c"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from IPython.display import *\n",
                "pandas.set_option('display.max_colwidth', -1)\n",
                "cmd = f'azdata bdc endpoint list'\n",
                "cmdOutput = !{cmd}\n",
                "endpoints = json.loads(''.join(cmdOutput))\n",
                "endpointsDataFrame = pandas.DataFrame(endpoints)\n",
                "endpointsDataFrame.columns = [' '.join(word[0].upper() + word[1:] for word in columnName.split()) for columnName in endpoints[0].keys()]\n",
                "display(HTML(endpointsDataFrame.to_html(index=False, render_links=True)))"
            ],
            "metadata": {
                "azdata_cell_guid": "2a8c8d5d-862c-4672-9309-38aa03afc4e6"
            },
            "outputs": [],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Connect to master SQL Server instance in Azure Data Studio**\r\n",
                "Click the link below to connect to the master SQL Server instance of the SQL Server 2019 Big Data Cluster."
            ],
            "metadata": {
                "azdata_cell_guid": "0bd809fa-8225-4954-a50c-da57ea167896"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "sqlEndpoints = [x for x in endpoints if x['name'] == 'sql-server-master']\r\n",
                "if sqlEndpoints and len(sqlEndpoints) == 1:\r\n",
                "    connectionParameter = '{\"serverName\":\"' + sqlEndpoints[0]['endpoint'] + '\",\"providerName\":\"MSSQL\",\"authenticationType\":\"SqlLogin\",\"userName\":\"sa\",\"password\":' + json.dumps(mssql_password) + '}'\r\n",
                "    display(HTML('<br/><a href=\"command:azdata.connect?' + html.escape(connectionParameter)+'\"><font size=\"3\">Click here to connect to master SQL Server instance</font></a><br/>'))\r\n",
                "else:\r\n",
                "    sys.exit('Could not find the master SQL Server instance endpoint')"
            ],
            "metadata": {
                "azdata_cell_guid": "d591785d-71aa-4c5d-9cbb-a7da79bca503"
            },
            "outputs": [],
            "execution_count": 10
        }
    ]
}