{
	"": [
		"--------------------------------------------------------------------------------------------",
		"Copyright (c) Microsoft Corporation. All rights reserved.",
		"Licensed under the Source EULA. See License.txt in the project root for license information.",
		"--------------------------------------------------------------------------------------------",
		"Do not edit this file. It is machine generated."
	],
	"version": "1.0.0",
	"contents": {
		"package": {
			"json.schemas.desc": "Hiermit werden Schemas zu JSON-Dateien im aktuellen Projekt zugeordnet.",
			"json.schemas.url.desc": "Eine URL zu einem Schema oder ein relativer Pfad zu einem Schema im aktuellen Verzeichnis",
			"json.schemas.fileMatch.desc": "Ein Array aus Dateimustern zum Abgleich beim Auflösen von JSON-Dateien in Schemas",
			"json.schemas.fileMatch.item.desc": "Ein Dateimuster, das \"*\" enthalten kann, zum Abgleich beim Auflösen von JSON-Dateien in Schemas",
			"json.schemas.schema.desc": "Die Schemadefinition für die angegebene URL. Das Schema muss nur angegeben werden, um Zugriffe auf die Schema-URL zu vermeiden.",
			"json.format.enable.desc": "Standard-JSON-Formatierer aktivieren/deaktivieren (Neustart erforderlich)",
			"mssqlCluster.uploadFiles": "Dateien hochladen",
			"mssqlCluster.mkdir": "Neues Verzeichnis",
			"mssqlCluster.deleteFiles": "Löschen",
			"mssqlCluster.previewFile": "Vorschau",
			"mssqlCluster.saveFile": "Speichern",
			"mssqlCluster.copyPath": "Pfad kopieren",
			"mssqlCluster.manageAccess": "Zugriff verwalten",
			"notebook.command.new": "Neues Notebook",
			"notebook.command.open": "Notebook öffnen",
			"tab.bigDataClusterDescription": "Aufgaben und Informationen zu Ihrem SQL Server-Big Data-Cluster",
			"title.bigDataCluster": "SQL Server-Big Data-Cluster",
			"title.submitSparkJob": "Spark-Auftrag übermitteln",
			"title.newSparkJob": "Neuer Spark-Auftrag",
			"title.openSparkHistory": "Spark-Verlauf anzeigen",
			"title.openYarnHistory": "Yarn-Verlauf anzeigen",
			"title.tasks": "Aufgaben",
			"title.installPackages": "Pakete installieren",
			"title.configurePython": "Python für Notebooks konfigurieren",
			"title.openClusterDashboard": "Cluster\r\nDashboard",
			"title.searchServers": "Suche: Server",
			"title.clearSearchServerResult": "Suche: Suchserverergebnisse löschen",
			"title.endpoints": "Dienstendpunkte",
			"title.books": "Notebooks",
			"title.showLogFile": "Protokolldatei anzeigen",
			"mssql.disabled": "Deaktiviert",
			"mssql.enabled": "Aktiviert",
			"mssql.exportNotebookToSql": "Notebook als SQL exportieren",
			"mssql.exportSqlAsNotebook": "SQL als Notebook exportieren",
			"mssql.configuration.title": "MSSQL-Konfiguration",
			"mssql.query.displayBitAsNumber": "BIT-Spalten als Zahlen (1 oder 0) anzeigen? Bei Festlegung auf FALSE werden BIT-Spalten als TRUE oder FALSE angezeigt.",
			"mssql.query.maxXmlCharsToStore": "Anzahl von XML-Zeichen, die nach dem Ausführen einer Abfrage gespeichert werden sollen",
			"mssql.format.alignColumnDefinitionsInColumns": "Sollen Spaltendefinitionen ausgerichtet werden?",
			"mssql.format.datatypeCasing": "Gibt an, ob Datentypen in Großbuchstaben, Kleinbuchstaben oder gar nicht formatiert werden sollen.",
			"mssql.format.keywordCasing": "Gibt an, ob Schlüsselwörter in Großbuchstaben, Kleinbuchstaben oder gar nicht formatiert werden sollen.",
			"mssql.format.placeCommasBeforeNextStatement": "Gibt an, dass Kommas in einer Liste am Anfang der einzelnen Anweisungen (z. B. \", mycolumn2\") und nicht am Ende platziert werden sollen: \"mycolumn1,\"",
			"mssql.format.placeSelectStatementReferencesOnNewLine": "Sollen Verweise auf Objekte in einer SELECT-Anweisung in separaten Zeilen angezeigt werden? Beispielsweise werden bei \"SELECT C1, C2 FROM T1\" C1 und C2 jeweils in separaten Zeilen angezeigt.",
			"mssql.logDebugInfo": "[Optional] Protokollieren Sie die Debugausgabe in der Konsole (Ansicht > Ausgabe), und wählen Sie dann in der Dropdownliste den geeigneten Ausgabekanal aus.",
			"mssql.tracingLevel": "[Optional] Protokolliergrad für Back-End-Dienste. Azure Data Studio generiert bei jedem Start einen Dateinamen, und falls die Datei bereits vorhanden ist, werden die Protokolleinträge an diese Datei angehängt. Zur Bereinigung alter Protokolldateien können die Einstellungen \"logRetentionMinutes\" und \"logFilesRemovalLimit\" verwendet werden. Bei Verwendung des Standardwerts für \"tracingLevel\" werden nur wenige Informationen protokolliert. Eine Änderung der Ausführlichkeit kann zu einem umfangreichen Protokollierungsaufkommen und einem hohen Speicherplatzbedarf für die Protokolle führen. \"Error\" umfasst kritische Meldungen, \"Warning\" umfasst alle Daten aus \"Error\" sowie Warnmeldungen, \"Information\" umfasst alle Daten aus \"Warning\" sowie Informationsmeldungen, \"Verbose\" umfasst ausführliche Informationen.",
			"mssql.logRetentionMinutes": "Anzahl von Minuten, für die Protokolldateien für Back-End-Dienste aufbewahrt werden sollen. Der Standardwert ist 1 Woche.",
			"mssql.logFilesRemovalLimit": "Die maximale Anzahl alter Dateien, die beim Start entfernt werden sollen, bei denen der mssql.logRetentionMinutes-Wert abgelaufen ist. Dateien, die aufgrund dieser Einschränkung nicht bereinigt werden, werden beim nächsten Start von Azure Data Studio bereinigt.",
			"mssql.intelliSense.enableIntelliSense": "Gibt an, ob IntelliSense aktiviert werden soll.",
			"mssql.intelliSense.enableErrorChecking": "Gibt an, ob die IntelliSense-Fehlerüberprüfung aktiviert werden soll.",
			"mssql.intelliSense.enableSuggestions": "Gibt an, ob IntelliSense-Vorschläge aktiviert werden sollen.",
			"mssql.intelliSense.enableQuickInfo": "Gibt an, ob IntelliSense-QuickInfo aktiviert werden soll.",
			"mssql.intelliSense.lowerCaseSuggestions": "Gibt an, ob IntelliSense-Vorschläge in Kleinbuchstaben angezeigt werden sollen.",
			"mssql.query.setRowCount": "Maximale Anzahl von Zeilen, die zurückgegeben werden sollen, bevor der Server die Verarbeitung Ihrer Abfrage beendet.",
			"mssql.query.textSize": "Maximale Größe von text- und ntext-Daten, die von einer SELECT-Anweisung zurückgegeben werden",
			"mssql.query.executionTimeout": "Ein Timeoutwert von 0 für die Ausführung kennzeichnet einen unbegrenzten Wartevorgang (kein Timeout).",
			"mssql.query.noCount": "SET NOCOUNT-Option aktivieren",
			"mssql.query.noExec": "SET NOEXEC-Option aktivieren",
			"mssql.query.parseOnly": "SET PARSEONLY-Option aktivieren",
			"mssql.query.arithAbort": "Set ARITHABORT-Option aktivieren",
			"mssql.query.statisticsTime": "SET STATISTICS TIME-Option aktivieren",
			"mssql.query.statisticsIO": "Set STATISTICS IO-Option aktivieren",
			"mssql.query.xactAbortOn": "SET XACT_ABORT ON-Option aktivieren",
			"mssql.query.transactionIsolationLevel": "SET TRANSACTION ISOLATION LEVEL-Option aktivieren",
			"mssql.query.deadlockPriority": "SET DEADLOCK_PRIORITY-Option aktivieren",
			"mssql.query.lockTimeout": "SET LOCK TIMEOUT-Option aktivieren (in Millisekunden)",
			"mssql.query.queryGovernorCostLimit": "SET QUERY_GOVERNOR_COST_LIMIT aktivieren",
			"mssql.query.ansiDefaults": "SET ANSI_DEFAULTS aktivieren",
			"mssql.query.quotedIdentifier": "SET QUOTED_IDENTIFIER aktivieren",
			"mssql.query.ansiNullDefaultOn": "SET ANSI_NULL_DFLT_ON aktivieren",
			"mssql.query.implicitTransactions": "SET IMPLICIT_TRANSACTIONS aktivieren",
			"mssql.query.cursorCloseOnCommit": "SET CURSOR_CLOSE_ON_COMMIT aktivieren",
			"mssql.query.ansiPadding": "SET ANSI_PADDING aktivieren",
			"mssql.query.ansiWarnings": "SET ANSI_WARNINGS aktivieren",
			"mssql.query.ansiNulls": "SET ANSI_NULLS aktivieren",
			"mssql.query.alwaysEncryptedParameterization": "Parametrisierung für Always Encrypted aktivieren",
			"mssql.ignorePlatformWarning": "[Optional] Keine Anzeige von Warnungen zu nicht unterstützten Plattformen.",
			"onprem.databaseProperties.recoveryModel": "Wiederherstellungsmodell",
			"onprem.databaseProperties.lastBackupDate": "Letzte Datenbanksicherung",
			"onprem.databaseProperties.lastLogBackupDate": "Letzte Protokollsicherung",
			"onprem.databaseProperties.compatibilityLevel": "Kompatibilitätsgrad",
			"onprem.databaseProperties.owner": "Besitzer",
			"onprem.serverProperties.serverVersion": "Version",
			"onprem.serverProperties.serverEdition": "Edition",
			"onprem.serverProperties.machineName": "Computername",
			"onprem.serverProperties.osVersion": "Betriebssystemversion",
			"cloud.databaseProperties.azureEdition": "Edition",
			"cloud.databaseProperties.serviceLevelObjective": "Tarif",
			"cloud.databaseProperties.compatibilityLevel": "Kompatibilitätsgrad",
			"cloud.databaseProperties.owner": "Besitzer",
			"cloud.serverProperties.serverVersion": "Version",
			"cloud.serverProperties.serverEdition": "Typ",
			"mssql.provider.displayName": "Microsoft SQL Server",
			"mssql.connectionOptions.connectionName.displayName": "Name (optional)",
			"mssql.connectionOptions.connectionName.description": "Benutzerdefinierter Name der Verbindung",
			"mssql.connectionOptions.serverName.displayName": "Server",
			"mssql.connectionOptions.serverName.description": "Name der SQL Server-Instanz",
			"mssql.connectionOptions.databaseName.displayName": "Datenbank",
			"mssql.connectionOptions.databaseName.description": "Der Name des anfänglichen Katalogs oder der ersten Datenbank in der Datenquelle",
			"mssql.connectionOptions.authType.displayName": "Authentifizierungstyp",
			"mssql.connectionOptions.authType.description": "Gibt die Methode für die Authentifizierung bei SQL Server an.",
			"mssql.connectionOptions.authType.categoryValues.sqlLogin": "SQL-Anmeldung",
			"mssql.connectionOptions.authType.categoryValues.integrated": "Windows-Authentifizierung",
			"mssql.connectionOptions.authType.categoryValues.azureMFA": "Azure Active Directory: universell mit MFA-Unterstützung",
			"mssql.connectionOptions.userName.displayName": "Benutzername",
			"mssql.connectionOptions.userName.description": "Gibt die Benutzer-ID an, die beim Herstellen einer Verbindung mit der Datenquelle verwendet werden soll.",
			"mssql.connectionOptions.password.displayName": "Kennwort",
			"mssql.connectionOptions.password.description": "Gibt das Kennwort an, das beim Herstellen einer Verbindung mit der Datenquelle verwendet werden soll.",
			"mssql.connectionOptions.applicationIntent.displayName": "Anwendungszweck",
			"mssql.connectionOptions.applicationIntent.description": "Deklariert den Anwendungsauslastungstyp beim Herstellen einer Verbindung mit einem Server.",
			"mssql.connectionOptions.asynchronousProcessing.displayName": "Asynchrone Verarbeitung",
			"mssql.connectionOptions.asynchronousProcessing.description": "Bei Festlegung auf TRUE wird die Verwendung der asynchronen Verarbeitung im .NET Framework-Datenanbieter ermöglicht.",
			"mssql.connectionOptions.connectTimeout.displayName": "Verbindungstimeout",
			"mssql.connectionOptions.connectTimeout.description": "Die Zeitspanne (in Sekunden), die auf eine Verbindung mit dem Server gewartet wird, bevor der Versuch beendet und ein Fehler generiert wird.",
			"mssql.connectionOptions.currentLanguage.displayName": "Aktuelle Sprache",
			"mssql.connectionOptions.currentLanguage.description": "Der Datensatzname der SQL Server-Sprache",
			"mssql.connectionOptions.columnEncryptionSetting.displayName": "Always Encrypted",
			"mssql.connectionOptions.columnEncryptionSetting.description": "Aktiviert oder deaktiviert Always Encrypted für die Verbindung.",
			"mssql.connectionOptions.enclaveAttestationProtocol.displayName": "Nachweisprotokoll",
			"mssql.connectionOptions.enclaveAttestationProtocol.description": "Gibt ein Protokoll zum Nachweis einer serverseitigen Enclave an, die mit Always Encrypted für Secure Enclaves verwendet wird.",
			"mssql.connectionOptions.enclaveAttestationProtocol.categoryValues.AAS": "Azure Attestation",
			"mssql.connectionOptions.enclaveAttestationProtocol.categoryValues.HGS": "Host-Überwachungsdienst",
			"mssql.connectionOptions.enclaveAttestationUrl.displayName": "Enclave-Nachweis-URL",
			"mssql.connectionOptions.enclaveAttestationUrl.description": "Gibt einen Endpunkt zum Nachweis einer serverseitigen Enclave an, die mit Always Encrypted für Secure Enclaves verwendet wird.",
			"mssql.connectionOptions.encrypt.displayName": "Verschlüsseln",
			"mssql.connectionOptions.encrypt.description": "Bei Festlegung auf TRUE verwendet SQL Server die SSL-Verschlüsselung für alle zwischen Client und Server gesendeten Daten, sofern auf dem Server ein Zertifikat installiert ist.",
			"mssql.connectionOptions.persistSecurityInfo.displayName": "Sicherheitsinformationen dauerhaft speichern",
			"mssql.connectionOptions.persistSecurityInfo.description": "Bei Festlegung auf FALSE werden sicherheitsrelevante Informationen, z. B. das Kennwort, nicht als Teil der Verbindung zurückgegeben.",
			"mssql.connectionOptions.trustServerCertificate.displayName": "Serverzertifikat vertrauen",
			"mssql.connectionOptions.trustServerCertificate.description": "Bei Festlegung auf TRUE (und encrypt=true) verwendet SQL Server die SSL-Verschlüsselung für alle zwischen Client und Server gesendeten Daten, ohne das Serverzertifikat zu überprüfen.",
			"mssql.connectionOptions.attachedDBFileName.displayName": "Dateiname der angefügten Datenbank",
			"mssql.connectionOptions.attachedDBFileName.description": "Der Name der primären Datei einer anfügbaren Datenbank, einschließlich des vollständigen Pfadnamens.",
			"mssql.connectionOptions.contextConnection.displayName": "Kontextverbindung",
			"mssql.connectionOptions.contextConnection.description": "Bei Festlegung auf TRUE muss die Verbindung aus dem SQL-Serverkontext stammen. Nur verfügbar bei Ausführung im SQL Server-Prozess.",
			"mssql.connectionOptions.port.displayName": "Port",
			"mssql.connectionOptions.connectRetryCount.displayName": "Anzahl der Verbindungswiederholungen",
			"mssql.connectionOptions.connectRetryCount.description": "Anzahl der Versuche zur Verbindungswiederherstellung",
			"mssql.connectionOptions.connectRetryInterval.displayName": "Intervall für Verbindungswiederholung",
			"mssql.connectionOptions.connectRetryInterval.description": "Verzögerung zwischen Versuchen zur Verbindungswiederherstellung",
			"mssql.connectionOptions.applicationName.displayName": "Anwendungsname",
			"mssql.connectionOptions.applicationName.description": "Der Name der Anwendung",
			"mssql.connectionOptions.workstationId.displayName": "Arbeitsstations-ID",
			"mssql.connectionOptions.workstationId.description": "Der Name der Arbeitsstation, die eine Verbindung mit SQL Server herstellt",
			"mssql.connectionOptions.pooling.displayName": "Pooling",
			"mssql.connectionOptions.pooling.description": "Bei Festlegung auf TRUE wird das Verbindungsobjekt aus dem geeigneten Pool abgerufen oder bei Bedarf erstellt und dem geeigneten Pool hinzugefügt.",
			"mssql.connectionOptions.maxPoolSize.displayName": "Maximale Poolgröße",
			"mssql.connectionOptions.maxPoolSize.description": "Die maximal zulässige Anzahl von Verbindungen im Pool",
			"mssql.connectionOptions.minPoolSize.displayName": "Minimale Poolgröße",
			"mssql.connectionOptions.minPoolSize.description": "Die mindestens erforderliche Anzahl von Verbindungen im Pool",
			"mssql.connectionOptions.loadBalanceTimeout.displayName": "Timeout für Lastenausgleich",
			"mssql.connectionOptions.loadBalanceTimeout.description": "Die Mindestzeitspanne (in Sekunden), für die diese Verbindung im Pool verbleiben soll, bevor sie zerstört wird",
			"mssql.connectionOptions.replication.displayName": "Replikation",
			"mssql.connectionOptions.replication.description": "Wird von SQL Server bei der Replikation verwendet.",
			"mssql.connectionOptions.attachDbFilename.displayName": "Dateiname der anzufügenden Datenbank",
			"mssql.connectionOptions.failoverPartner.displayName": "Failoverpartner",
			"mssql.connectionOptions.failoverPartner.description": "Der Name oder die Netzwerkadresse der SQL Server-Instanz, die als Failoverpartner fungiert",
			"mssql.connectionOptions.multiSubnetFailover.displayName": "Multisubnetzfailover",
			"mssql.connectionOptions.multipleActiveResultSets.displayName": "Mehrere aktive Resultsets",
			"mssql.connectionOptions.multipleActiveResultSets.description": "Bei Festlegung auf TRUE können mehrere Resultsets zurückgegeben und aus einer Verbindung gelesen werden.",
			"mssql.connectionOptions.packetSize.displayName": "Paketgröße",
			"mssql.connectionOptions.packetSize.description": "Größe der Netzwerkpakete (in Byte), die bei der Kommunikation mit einer Instanz von SQL Server verwendet werden",
			"mssql.connectionOptions.typeSystemVersion.displayName": "Typsystemversion",
			"mssql.connectionOptions.typeSystemVersion.description": "Gibt an, welches Servertypsystem der Anbieter über den DataReader offenlegt.",
			"databasesListProperties.name": "Name",
			"databasesListProperties.status": "Status",
			"databasesListProperties.size": "Größe (MB)",
			"databasesListProperties.lastBackup": "Letzte Sicherung",
			"objectsListProperties.name": "Name"
		},
		"dist/localizedConstants": {
			"msgMissingNodeContext": "Es wurde ein Knotenbefehl aufgerufen, ohne dass ein Knoten übergeben wurde.",
			"mssql.manageAccessTitle": "Zugriff verwalten",
			"mssql.locationTitle": "Speicherort: ",
			"mssql.permissionsTitle": "Berechtigungen",
			"mssql.ownerPostfix": "– Besitzer",
			"mssql.owner": "Besitzer",
			"mssql.group": "Gruppe",
			"mssql.owningGroupPostfix": "– Besitzergruppe",
			"mssql.everyone": "Beliebige andere Person",
			"mssql.userLabel": "Benutzer",
			"mssql.groupLabel": "Gruppe",
			"mssql.accessHeader": "Zugriff",
			"mssql.defaultHeader": "Standard",
			"mssql.delete": "Löschen",
			"mssql.stickyHeader": "Sticky Bit",
			"mssql.inheritDefaultsLabel": "Standardwerte erben",
			"mssql.readHeader": "Lesen",
			"mssql.writeHeader": "Schreiben",
			"mssql.executeHeader": "Ausführen",
			"mssql.addUserOrGroup": "Benutzer oder Gruppe hinzufügen",
			"mssql.enterNamePlaceholder": "Namen eingeben",
			"mssql.addLabel": "Hinzufügen",
			"mssql.namedUsersAndGroups": "Benannte Benutzer und Gruppen",
			"mssql.defaultUserAndGroups": "Standardbenutzer und -gruppen",
			"mssql.userOrGroupIcon": "Symbol für Benutzer oder Gruppe",
			"mssql.apply": "Anwenden",
			"mssql.applyRecursively": "Rekursiv anwenden",
			"mssql.errorApplyingAclChanges": "Unerwarteter Fehler beim Anwenden von Änderungen: {0}",
			"sparkJobSubmission.LocalFileDestinationHint": "Lokale Datei wird in HDFS hochgeladen. ",
			"sparkJobSubmission.SubmissionEndMessage": ".......................... Ende der Spark-Auftragsübermittlung ............................",
			"sparkJobSubmission.PrepareUploadingFile": "Die Datei wird aus dem lokalen Ordner \"{0}\" in den HDFS-Ordner hochgeladen: {1}",
			"sparkJobSubmission.UploadingFileSucceeded": "Die Datei wurde erfolgreich in den Cluster hochgeladen.",
			"sparkJobSubmission.UploadingFileFailed": "Fehler beim Hochladen der Datei in den Cluster. {0}",
			"sparkJobSubmission.PrepareSubmitJob": "Der Auftrag \"{0}\" wird übermittelt... ",
			"sparkJobSubmission.SubmitJobFinished": "Der Spark-Auftrag wurde übermittelt.",
			"sparkJobSubmission.SubmitJobFailed": "Fehler bei der Spark-Auftragsübermittlung. {0} ",
			"sparkJobSubmission.YarnUIMessage": "YarnUI-URL: {0} ",
			"sparkJobSubmission.SparkHistoryLinkMessage": "Spark-Verlaufs-URL: {0} ",
			"sparkJobSubmission.GetApplicationIdFailed": "Fehler beim Abrufen der Anwendungs-ID. {0}",
			"sparkJobSubmission.LocalFileNotExisted": "Die lokale Datei \"{0}\" ist nicht vorhanden. ",
			"sparkJobSubmission.NoSqlBigDataClusterFound": "Es wurde kein SQL Server-Big Data-Cluster gefunden.",
			"sparkConnectionRequired": "Stellen Sie eine Verbindung mit dem Spark-Cluster her, bevor Sie den Verlauf von \"{0}\" anzeigen."
		},
		"dist/objectExplorerNodeProvider/fileSources": {
			"maxSizeNotice": "HINWEIS: Diese Datei wurde zur Vorschau bei \"{0}\" abgeschnitten. ",
			"maxSizeReached": "Die Datei wurde zur Vorschau bei \"{0}\" abgeschnitten."
		},
		"dist/objectExplorerNodeProvider/command": {
			"progress": "$(sync~spin) {0}...",
			"cancelTooltip": "Abbrechen",
			"cancel": "Vorgang abbrechen?",
			"mssql.searchServers": "Servernamen suchen"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionService": {
			"sparkJobSubmission.LivyNoBatchIdReturned": "In der Antwort wurde keine Batch-ID für Spark-Aufträge zurückgegeben.{0}[Fehler] {1}",
			"sparkJobSubmission.LivyNoLogReturned": "Innerhalb der Antwort wird kein Protokoll zurückgegeben.{0}[Fehler] {1}"
		},
		"dist/sqlClusterLookUp": {
			"promptBDCUsername": "{0}Geben Sie den Benutzernamen zum Herstellen einer Verbindung mit dem BDC-Controller an:",
			"promptBDCPassword": "Geben Sie das Kennwort zum Herstellen einer Verbindung mit dem BDC-Controller an.",
			"bdcConnectError": "Fehler: {0}. ",
			"usernameAndPasswordRequired": "Benutzername und Kennwort sind erforderlich."
		},
		"dist/objectExplorerNodeProvider/hdfsCommands": {
			"allFiles": "Alle Dateien",
			"lblUploadFiles": "Hochladen",
			"uploading": "Dateien werden in HDFS hochgeladen",
			"uploadCanceled": "Der Uploadvorgang wurde abgebrochen.",
			"uploadError": "Fehler beim Hochladen von Dateien: {0}",
			"makingDir": "Das Verzeichnis wird erstellt.",
			"mkdirCanceled": "Der Vorgang wurde abgebrochen.",
			"mkDirError": "Fehler beim Erstellen des Verzeichnisses: {0}",
			"enterDirName": "Verzeichnisnamen eingeben",
			"deleteError": "Fehler beim Löschen von Dateien: {0}",
			"msgDeleteFolder": "Möchten Sie diesen Ordner und den zugehörigen Inhalt löschen?",
			"msgDeleteFile": "Möchten Sie diese Datei löschen?",
			"saving": "Die HDFS-Dateien werden gespeichert.",
			"saveCanceled": "Der Speichervorgang wurde abgebrochen.",
			"saveError": "Fehler beim Speichern der Datei: {0}",
			"previewing": "Die Vorschau wird generiert.",
			"previewError": "Fehler bei der Vorschau der Datei: {0}",
			"copyPathError": "Fehler beim Kopieren des Pfads: {0}",
			"manageAccessError": "Unerwarteter Fehler beim Öffnen des Dialogfelds \"Zugriff verwalten\": {0}"
		},
		"dist/hdfs/webhdfs": {
			"webhdfs.invalidDataStructure": "Ungültige Datenstruktur.",
			"webhdfs.missingProperties": "Der WebHDFS-Client kann aufgrund von fehlenden Optionen nicht erstellt werden: ${0}",
			"webhdfs.undefinedArgument": "\"${0}\" ist nicht definiert.",
			"webhdfs.httpError400": "Fehlerhafte Anforderung.",
			"webhdfs.httpError401": "Nicht autorisiert",
			"webhdfs.httpError403": "Unzulässig",
			"webhdfs.httpError404": "Nicht gefunden",
			"webhdfs.httpError500": "Interner Serverfehler",
			"webhdfs.unknownError": "Unbekannter Fehler",
			"webhdfs.unexpectedRedirect": "Unerwartete Umleitung"
		},
		"dist/objectExplorerNodeProvider/connection": {
			"connectionInfoUndefined": "\"ConnectionInfo\" ist nicht definiert.",
			"connectionInfoOptionsUndefined": "\"ConnectionInfo.options\" ist nicht definiert.",
			"connectionInfoOptionsMissingProperties": "In \"connectionInfo.options\" fehlen einige Eigenschaften: {0}"
		},
		"dist/telemetry": {
			"viewKnownIssuesText": "Bekannte Probleme anzeigen",
			"serviceCrashMessage": "Die Komponente \"{0}\" wurde unerwartet beendet. Starten Sie Azure Data Studio neu."
		},
		"dist/main": {
			"msgSampleCodeDataFrame": "Dieser Beispielcode lädt die Datei in einen Datenrahmen und zeigt die ersten 10 Ergebnisse an.",
			"mssql.errorConvertingToNotebook": "Fehler beim Konvertieren des SQL-Dokuments in ein Notebook: {0}",
			"mssql.errorConvertingToSQL": "Fehler beim Konvertieren des Notebook-Dokuments in SQL: {0}",
			"notebookFileType": "Notebooks",
			"unsupportedFileType": "Es werden nur IPYNB-Notebooks unterstützt.",
			"noController": "Der Controllerendpunkt für diese Instanz wurde nicht gefunden."
		},
		"dist/hdfs/hdfsModel": {
			"mssql.recursivePermissionOpStarted": "Die Berechtigungsänderungen werden unter \"{0}\" rekursiv angewendet.",
			"mssql.recursivePermissionOpSucceeded": "Die Berechtigungsänderungen wurden erfolgreich angewendet.",
			"mssql.recursivePermissionOpProgress": "Die Berechtigungsänderungen werden auf \"{0}\" angewendet.",
			"mssql.recursivePermissionOpError": "Fehler beim Anwenden von Berechtigungsänderungen: {0}"
		},
		"dist/prompts/confirm": {
			"msgYes": "Ja",
			"msgNo": "Nein"
		},
		"dist/sparkFeature/dialog/dialogCommands": {
			"selectOtherServer": "Andere SQL Server-Instanz auswählen",
			"sparkJobSubmission.PleaseSelectSqlWithCluster": "Wählen Sie SQL Server mit Big Data-Cluster aus.",
			"sparkJobSubmission.NoSqlSelected": "Es ist keine SQL Server-Instanz ausgewählt.",
			"errorNotSqlBigDataCluster": "Der ausgewählte Server gehört nicht zu einem SQL Server-Big Data-Cluster.",
			"sparkJobSubmission.GetFilePathFromSelectedNodeFailed": "Fehler beim Abrufen des Dateipfads: {0}"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionDialog": {
			"sparkJobSubmission.SparkJobSubmissionDialogInitializeError": "Die Parameter für \"SparkJobSubmissionDialog\" sind ungültig.",
			"sparkJobSubmission.DialogTitleNewJob": "Neuer Auftrag",
			"sparkJobSubmission.DialogCancelButton": "Abbrechen",
			"sparkJobSubmission.DialogSubmitButton": "Übermitteln",
			"sparkJobSubmission.SubmitSparkJob": "{0} Spark-Auftragsübermittlung:",
			"sparkJobSubmission.SubmissionStartMessage": ".......................... Start der Spark-Auftragsübermittlung .........................."
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionModel": {
			"sparkJobSubmission.SparkJobSubmissionModelInitializeError": "Die Parameter für \"SparkJobSubmissionModel\" sind ungültig.",
			"sparkJobSubmission.submissionArgsIsInvalid": "\"submissionArgs\" ist ungültig. ",
			"sparkJobSubmission.LivyBatchIdIsInvalid": "\"livyBatchId\" ist ungültig. ",
			"sparkJobSubmission.GetApplicationIdTimeOut": "Timeout beim Abrufen der Anwendungs-ID. {0}[Protokoll]   {1}",
			"sparkJobSubmission.localFileOrFolderNotSpecified.": "Die localFilePath- oder hdfsFolderPath-Eigenschaft wurde nicht angegeben. ",
			"sparkJobSubmission.PathNotSpecified.": "Der Eigenschaftspfad wurde nicht angegeben. "
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkConfigurationTab": {
			"sparkJobSubmission.GeneralTabName": "ALLGEMEIN",
			"sparkJobSubmission.JobNamePlaceHolder": "Namen eingeben...",
			"sparkJobSubmission.JobName": "Auftragsname",
			"sparkJobSubmission.SparkCluster": "Spark-Cluster",
			"sparkJobSubmission.FilePathPlaceHolder": "Pfad zu einer JAR- oder PY-Datei",
			"sparkJobSubmission.LocalFileDestinationHintWithPath": "Die ausgewählte lokale Datei wird in HDFS hochgeladen: {0}",
			"sparkJobSubmission.MainFilePath": "JAR-/PY-Datei",
			"sparkJobSubmission.MainClass": "Hauptklasse",
			"sparkJobSubmission.Arguments": "Argumente",
			"sparkJobSubmission.ArgumentsTooltip": "Befehlszeilenargumente, die in Ihrer Hauptklasse verwendet werden. Mehrere Argumente müssen durch Leerzeichen voneinander getrennt werden.",
			"sparkJobSubmission.NotSpecifyJobName": "Der Eigenschaftsauftragsname wurde nicht angegeben.",
			"sparkJobSubmission.NotSpecifyJARPYPath": "Die JAR-/PY-Eigenschaftsdatei wurde nicht angegeben.",
			"sparkJobSubmission.NotSpecifyMainClass": "Die Hauptklasse der Eigenschaft wurde nicht angegeben.",
			"sparkJobSubmission.HDFSFileNotExistedWithPath": "\"{0}\" ist nicht im Cluster vorhanden, oder es wurde eine Ausnahme ausgelöst. ",
			"sparkJobSubmission.HDFSFileNotExisted": "Die angegebene HDFS-Datei ist nicht vorhanden. ",
			"sparkSelectLocalFile": "Auswählen",
			"sparkJobSubmission.SelectFileError": "Fehler beim Suchen der Datei: {0}"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkAdvancedTab": {
			"sparkJobSubmission.AdvancedTabName": "ERWEITERT",
			"sparkJobSubmission.ReferenceJarList": "JAR-Referenzdateien",
			"sparkJobSubmission.ReferenceJarListToolTip": "JAR-Dateien, die im Executor-Arbeitsverzeichnis platziert werden sollen. Der JAR-Pfad muss ein HDFS-Pfad sein. Mehrere Pfade müssen durch ein Semikolon (;) voneinander getrennt werden.",
			"sparkJobSubmission.ReferencePyList": "PY-Referenzdateien",
			"sparkJobSubmission.ReferencePyListTooltip": "PY-Dateien, die im Executor-Arbeitsverzeichnis platziert werden sollen. Der Dateipfad muss ein HDFS-Pfad sein. Mehrere Pfade müssen durch ein Semikolon (;) voneinander getrennt werden.",
			"sparkJobSubmission.ReferenceFilesList": "Referenzdateien",
			"sparkJobSubmission.ReferenceFilesListTooltip": "Dateien, die im Executor-Arbeitsverzeichnis platziert werden sollen. Der Dateipfad muss ein HDFS-Pfad sein. Mehrere Pfade müssen durch ein Semikolon (;) voneinander getrennt werden.",
			"sparkJobSubmission.driverMemory": "Treiberarbeitsspeicher",
			"sparkJobSubmission.driverMemoryTooltip": "Die Menge an Arbeitsspeicher, die dem Treiber zugeordnet werden soll. Geben Sie Einheiten als Teil des Werts an. Beispiel: 512M oder 2G.",
			"sparkJobSubmission.driverCores": "Treiberkerne",
			"sparkJobSubmission.driverCoresTooltip": "Die Anzahl von CPU-Kernen, die dem Treiber zugeordnet werden sollen.",
			"sparkJobSubmission.executorMemory": "Executorspeicher",
			"sparkJobSubmission.executorMemoryTooltip": "Die Menge an Arbeitsspeicher, die dem Executor zugeordnet werden soll. Geben Sie Einheiten als Teil des Werts an. Beispiel: 512M oder 2G.",
			"sparkJobSubmission.executorCores": "Executorkerne",
			"sparkJobSubmission.executorCoresTooltip": "Die Anzahl von CPU-Kernen, die dem Executor zugeordnet werden sollen.",
			"sparkJobSubmission.executorCount": "Anzahl von Executors",
			"sparkJobSubmission.executorCountTooltip": "Anzahl der auszuführenden Executorinstanzen.",
			"sparkJobSubmission.queueName": "Warteschlangenname",
			"sparkJobSubmission.queueNameTooltip": "Name der Spark-Warteschlange, in der die Sitzung ausgeführt wird.",
			"sparkJobSubmission.configValues": "Konfigurationswerte",
			"sparkJobSubmission.configValuesTooltip": "Liste von Name-Wert-Paaren, die Spark-Konfigurationswerte enthalten. Als JSON-Wörterbuch codiert. Beispiel: '{\"name\":\"wert\", \"name2\":\"wert2\"}'."
		},
		"dist/objectExplorerNodeProvider/objectExplorerNodeProvider": {
			"promptUsername": "Geben Sie den Benutzernamen zum Herstellen einer Verbindung mit HDFS an:",
			"prmptPwd": "Geben Sie das Kennwort für die Verbindung mit HDFS an:",
			"sessionNotFound": "Die Sitzung für den Knoten \"{0}\" ist nicht vorhanden.",
			"notifyError": "Fehler bei Benachrichtigung über Knotenänderung: {0}",
			"hdfsFolder": "HDFS",
			"rootLabel": "Stamm"
		},
		"dist/objectExplorerNodeProvider/hdfsProvider": {
			"errorExpanding": "Fehler: {0}",
			"errDeleteConnectionNode": "Eine Verbindung kann nicht gelöscht werden. Nur Unterordner und Dateien können gelöscht werden."
		},
		"dist/objectExplorerNodeProvider/cancelableStream": {
			"streamCanceled": "Der Streamvorgang wurde vom Benutzer abgebrochen."
		},
		"dist/dashboard/serviceEndpoints": {
			"grafana": "Metrikdashboard",
			"kibana": "Dashboard für Protokollsuche",
			"sparkHistory": "Dashboard zum Verwalten und Überwachen von Spark-Aufträgen",
			"yarnHistory": "Dashboard zur Spark-Diagnose und -Überwachung",
			"copyText": "Kopieren",
			"endpoint.appproxy": "Anwendungsproxy",
			"endpoint.controller": "Clusterverwaltungsdienst",
			"endpoint.gateway": "Gateway für den Zugriff auf HDFS-Dateien, Spark",
			"endpoint.managementproxy": "Verwaltungsproxy",
			"endpoint.mgmtproxy": "Verwaltungsproxy",
			"endpoint.sqlServerEndpoint": "Front-End der SQL Server-Masterinstanz",
			"endpoint.grafana": "Metrikdashboard",
			"endpoint.kibana": "Dashboard für Protokollsuche",
			"endpoint.yarnHistory": "Dashboard zur Spark-Diagnose und -Überwachung",
			"endpoint.sparkHistory": "Dashboard zum Verwalten und Überwachen von Spark-Aufträgen",
			"endpoint.webhdfs": "HDFS-Dateisystemproxy",
			"endpoint.livy": "Proxy zum Ausführen von Spark-Anweisungen, -Aufträgen und -Anwendungen"
		},
		"dist/sqlToolsServer": {
			"serviceStartedStatusMsg": "\"{0}\" wurde gestartet.",
			"startingServiceStatusMsg": "\"{0}\" wird gestartet.",
			"failedToStartServiceErrorMsg": "Fehler beim Starten von \"{0}\".",
			"installingServiceChannelMsg": "\"{0}\" wird in \"{1}\" installiert.",
			"installingServiceStatusMsg": "\"{0}\" wird installiert.",
			"installedServiceChannelMsg": "\"{0}\" wurde installiert.",
			"downloadingServiceChannelMsg": "\"{0}\" wird heruntergeladen.",
			"downloadingServiceSizeChannelMsg": "({0} KB)",
			"downloadingServiceStatusMsg": "\"{0}\" wird heruntergeladen.",
			"downloadServiceDoneChannelMsg": "Die Installation von {0} wurde abgeschlossen.",
			"entryExtractedChannelMsg": "{0} extrahiert ({1}/{2})"
		},
		"dist/features": {
			"mssql.missingLinkedAzureAccount": "Azure Data Studio muss Azure Key Vault kontaktieren, um auf einen Spaltenhauptschlüssel für Always Encrypted zuzugreifen, aber es ist kein verknüpftes Azure-Konto verfügbar. Fügen Sie ein verknüpftes Azure-Konto hinzu, und wiederholen Sie die Abfrage.",
			"mssql.chooseLinkedAzureAccount": "Wählen Sie ein verknüpftes Azure-Konto aus:",
			"mssql.canceledLinkedAzureAccountSelection": "Azure Data Studio muss Azure Key Vault kontaktieren, um auf einen Spaltenhauptschlüssel für Always Encrypted zuzugreifen, aber es wurde kein verknüpftes Azure-Konto ausgewählt. Wiederholen Sie die Abfrage, und wählen Sie bei Aufforderung ein verknüpftes Azure-Konto aus.",
			"mssql.insufficientlyPrivelagedAzureAccount": "Das konfigurierte Azure-Konto für \"{0}\" verfügt nicht über ausreichende Berechtigungen für Azure Key Vault, um auf einen Spaltenhauptschlüssel für Always Encrypted zuzugreifen."
		}
	}
}