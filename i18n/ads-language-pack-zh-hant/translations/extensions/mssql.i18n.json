{
	"": [
		"--------------------------------------------------------------------------------------------",
		"Copyright (c) Microsoft Corporation. All rights reserved.",
		"Licensed under the Source EULA. See License.txt in the project root for license information.",
		"--------------------------------------------------------------------------------------------",
		"Do not edit this file. It is machine generated."
	],
	"version": "1.0.0",
	"contents": {
		"package": {
			"json.schemas.desc": "在結構描述與目前專案的 JSON 檔案之間建立關聯",
			"json.schemas.url.desc": "目前目錄中的結構描述 URL 或結構描述相對路徑",
			"json.schemas.fileMatch.desc": "檔案模式陣列，在將 JSON 檔案解析成結構描述時的比對對象。",
			"json.schemas.fileMatch.item.desc": "可包含 '*' 的檔案模式，在將 JSON 檔案解析成結構描述時的比對對象。",
			"json.schemas.schema.desc": "指定 URL 的結構描述定義。只須提供結構描述以避免存取結構描述 URL。",
			"json.format.enable.desc": "啟用/停用預設 JSON 格式器 (需要重新啟動)",
			"mssqlCluster.uploadFiles": "上傳檔案",
			"mssqlCluster.mkdir": "新增目錄",
			"mssqlCluster.deleteFiles": "刪除",
			"mssqlCluster.previewFile": "預覽",
			"mssqlCluster.saveFile": "儲存",
			"mssqlCluster.copyPath": "複製路徑",
			"mssqlCluster.manageAccess": "管理存取權",
			"notebook.command.new": "新增 Notebook",
			"notebook.command.open": "開啟 Notebook",
			"tab.bigDataClusterDescription": "SQL Server 巨量資料叢集的工作和資訊",
			"title.bigDataCluster": "SQL Server 巨量資料叢集",
			"title.submitSparkJob": "提交 Spark 作業",
			"title.newSparkJob": "新增 Spark 作業",
			"title.openSparkHistory": "檢視 Spark 歷程記錄",
			"title.openYarnHistory": "檢視 Yarn 歷程記錄",
			"title.tasks": "工作",
			"title.installPackages": "安裝套件",
			"title.configurePython": "為 Notebooks 設定 Python",
			"title.searchServers": "搜尋: 伺服器",
			"title.clearSearchServerResult": "搜尋: 清除搜尋伺服器結果",
			"title.endpoints": "服務端點",
			"title.books": "Notebooks",
			"title.showLogFile": "顯示記錄檔",
			"mssql.configuration.title": "MSSQL 設定",
			"mssql.query.displayBitAsNumber": "BIT 資料行是否顯示為數字 (1 或 0)? 若為 False，BIT 資料行將會顯示為 'True' 或 'False'",
			"mssql.format.alignColumnDefinitionsInColumns": "行定義是否一致?",
			"mssql.format.datatypeCasing": "是否將資料類型轉換為大寫，小寫或無 (不轉換)",
			"mssql.format.keywordCasing": "是否將關鍵字轉換為大寫，小寫或無 (不轉換)",
			"mssql.format.placeCommasBeforeNextStatement": "逗號是否放在 list 中每個語句的開頭，例如: \", mycolumn2\" 而非在結尾，例如: \"mycolumn1,\"",
			"mssql.format.placeSelectStatementReferencesOnNewLine": "在 select 陳述式中參考的物件是否要分行處理? 以 'SELECT C1, C2 FROM T1' 為例，C1 與 C2 將會分行顯示",
			"mssql.logDebugInfo": "[選用] 將偵錯記錄輸出至主控台 ([檢視] -> [輸出])，並從下拉式清單選取適當的輸出通道",
			"mssql.tracingLevel": "[選用] 後端服務的記錄層級。每當 Azure Data Studio 啟動，或是檔案已經有附加至該檔案的記錄項目時，Azure Data Studio 都會產生檔案名稱。如需清除舊記錄檔，請查看 logRetentionMinutes 和 logFilesRemovalLimit 設定。預設 tracingLevel 不會記錄太多項目。變更詳細資訊可能會導致大量記錄和記錄的磁碟空間需求。錯誤包含嚴重，警告包含錯誤，資訊包含警告而詳細資訊包含資訊",
			"mssql.logRetentionMinutes": "為後端服務保留記錄檔的分鐘數。預設為 1 週。",
			"mssql.logFilesRemovalLimit": "具有到期的 logRetentionMinutes，且要於啟動時移除的舊檔案數上限。因為此限制而未清除的檔案，將於下次 Azure Data Studio 啟動時受到清除。",
			"ignorePlatformWarning": "[選用] 不要顯示不支援的平台警告",
			"onprem.databaseProperties.recoveryModel": "復原模式",
			"onprem.databaseProperties.lastBackupDate": "上次資料庫備份",
			"onprem.databaseProperties.lastLogBackupDate": "上次記錄備份",
			"onprem.databaseProperties.compatibilityLevel": "相容性層級",
			"onprem.databaseProperties.owner": "擁有者",
			"onprem.serverProperties.serverVersion": "版本",
			"onprem.serverProperties.serverEdition": "版本",
			"onprem.serverProperties.machineName": "電腦名稱",
			"onprem.serverProperties.osVersion": "作業系統版本",
			"cloud.databaseProperties.azureEdition": "版本",
			"cloud.databaseProperties.serviceLevelObjective": "定價層",
			"cloud.databaseProperties.compatibilityLevel": "相容性層級",
			"cloud.databaseProperties.owner": "擁有者",
			"cloud.serverProperties.serverVersion": "版本",
			"cloud.serverProperties.serverEdition": "類型",
			"mssql.provider.displayName": "Microsoft SQL Server",
			"mssql.connectionOptions.connectionName.displayName": "名稱 (選用)",
			"mssql.connectionOptions.connectionName.description": "連線的自訂名稱",
			"mssql.connectionOptions.serverName.displayName": "伺服器",
			"mssql.connectionOptions.serverName.description": "SQL Server 執行個體的名稱",
			"mssql.connectionOptions.databaseName.displayName": "資料庫",
			"mssql.connectionOptions.databaseName.description": "資料來源中，初始類別目錄或資料庫的名稱。",
			"mssql.connectionOptions.authType.displayName": "驗證類型",
			"mssql.connectionOptions.authType.description": "指定向 SQL Server 驗證的方法",
			"mssql.connectionOptions.authType.categoryValues.sqlLogin": "SQL 登入",
			"mssql.connectionOptions.authType.categoryValues.integrated": "Windows 驗證",
			"mssql.connectionOptions.authType.categoryValues.azureMFA": "Azure Active Directory - MFA 通用支援",
			"mssql.connectionOptions.userName.displayName": "使用者名稱",
			"mssql.connectionOptions.userName.description": "代表要在連線至資料來源時使用的使用者識別碼",
			"mssql.connectionOptions.password.displayName": "密碼",
			"mssql.connectionOptions.password.description": "代表要在連線至資料來源時使用的密碼",
			"mssql.connectionOptions.applicationIntent.displayName": "應用程式的意圖",
			"mssql.connectionOptions.applicationIntent.description": "在連線至伺服器時宣告應用程式工作負載類型",
			"mssql.connectionOptions.asynchronousProcessing.displayName": "非同步處理",
			"mssql.connectionOptions.asynchronousProcessing.description": "若為 True，則允許使用 .Net Framework Data Provider 中的非同步功能",
			"mssql.connectionOptions.connectTimeout.displayName": "連線逾時",
			"mssql.connectionOptions.connectTimeout.description": "終止嘗試並產生錯誤前，要等待伺服器連線的時間長度 (秒)",
			"mssql.connectionOptions.currentLanguage.displayName": "目前的語言",
			"mssql.connectionOptions.currentLanguage.description": "SQL Server 語言記錄名稱",
			"mssql.connectionOptions.columnEncryptionSetting.displayName": "資料行加密",
			"mssql.connectionOptions.columnEncryptionSetting.description": "連線上所有命令的預設資料行加密設定",
			"mssql.connectionOptions.encrypt.displayName": "加密",
			"mssql.connectionOptions.encrypt.description": "若為 True，則 SQL Server 會在伺服器已安裝憑證的情況下，對用戶端和伺服器間傳送的所有資料使用 SSL 加密",
			"mssql.connectionOptions.persistSecurityInfo.displayName": "持續安全性資訊",
			"mssql.connectionOptions.persistSecurityInfo.description": "若為 False，則不會於連線中傳回密碼等安全性敏感資訊",
			"mssql.connectionOptions.trustServerCertificate.displayName": "信任伺服器憑證",
			"mssql.connectionOptions.trustServerCertificate.description": "若為 True (且 encrypt=true)，則 SQL Server 會對用戶端和伺服器間傳送的所有資料使用 SSL 加密，而不驗證伺服器憑證",
			"mssql.connectionOptions.attachedDBFileName.displayName": "已附加的 DB 檔案名稱",
			"mssql.connectionOptions.attachedDBFileName.description": "主要檔案的名稱，包含可附加資料庫的完整路徑名稱",
			"mssql.connectionOptions.contextConnection.displayName": "內容連線",
			"mssql.connectionOptions.contextConnection.description": "若為 True，則表示連線應來自 SQL 伺服器內容。僅可在於 SQL Server 處理序中執行時可用",
			"mssql.connectionOptions.port.displayName": "連接埠",
			"mssql.connectionOptions.connectRetryCount.displayName": "連線重試計數",
			"mssql.connectionOptions.connectRetryCount.description": "嘗試還原連線的次數",
			"mssql.connectionOptions.connectRetryInterval.displayName": "連線重試間隔",
			"mssql.connectionOptions.connectRetryInterval.description": "嘗試還原連線之間的延遲",
			"mssql.connectionOptions.applicationName.displayName": "應用程式名稱",
			"mssql.connectionOptions.applicationName.description": "應用程式的名稱",
			"mssql.connectionOptions.workstationId.displayName": "工作站識別碼",
			"mssql.connectionOptions.workstationId.description": "連線至 SQL Server 的工作站名稱",
			"mssql.connectionOptions.pooling.displayName": "共用",
			"mssql.connectionOptions.pooling.description": "若為 True，則會從適當的集區提取連線物件，或在有需要時建立並新增至適當的集區",
			"mssql.connectionOptions.maxPoolSize.displayName": "集區大小上限",
			"mssql.connectionOptions.maxPoolSize.description": "集區中允許的連線數上限",
			"mssql.connectionOptions.minPoolSize.displayName": "集區大小下限",
			"mssql.connectionOptions.minPoolSize.description": "集區中允許的連線數下限",
			"mssql.connectionOptions.loadBalanceTimeout.displayName": "負載平衡逾時",
			"mssql.connectionOptions.loadBalanceTimeout.description": "此連線在終結前於集區中存留的時間下限 (秒)",
			"mssql.connectionOptions.replication.displayName": "複寫",
			"mssql.connectionOptions.replication.description": "由 SQL Server 在複寫中使用",
			"mssql.connectionOptions.attachDbFilename.displayName": "附加 DB 檔案名稱",
			"mssql.connectionOptions.failoverPartner.displayName": "容錯移轉夥伴",
			"mssql.connectionOptions.failoverPartner.description": "充當容錯移轉夥伴之 SQL Server 執行個體的名稱或網路位址",
			"mssql.connectionOptions.multiSubnetFailover.displayName": "多重子網路容錯移轉",
			"mssql.connectionOptions.multipleActiveResultSets.displayName": "Multiple Active Result Set",
			"mssql.connectionOptions.multipleActiveResultSets.description": "若為 True，則可傳回多個結果集並從一個連線讀取",
			"mssql.connectionOptions.packetSize.displayName": "封包大小",
			"mssql.connectionOptions.packetSize.description": "用於和 SQL Server 執行個體通訊之網路封包的大小 (位元組)",
			"mssql.connectionOptions.typeSystemVersion.displayName": "鍵入系統版本",
			"mssql.connectionOptions.typeSystemVersion.description": "指出會依序透過 DataReader 公開的伺服器類型系統和提供者"
		},
		"dist/localizedConstants": {
			"msgMissingNodeContext": "已呼叫節點命令，但未傳遞任何節點",
			"mssql.manageAccessTitle": "管理存取權",
			"mssql.locationTitle": "位置:",
			"mssql.permissionsTitle": "權限",
			"mssql.ownerPostfix": "- 擁有者",
			"mssql.owningGroupPostfix": "- 擁有群組",
			"mssql.everyone": "其他人",
			"mssql.userLabel": "使用者",
			"mssql.groupLabel": "群組",
			"mssql.accessHeader": "存取",
			"mssql.defaultHeader": "預設",
			"mssql.delete": "刪除",
			"mssql.stickyHeader": "黏性",
			"mssql.inheritDefaultsLabel": "繼承預設值",
			"mssql.readHeader": "讀取",
			"mssql.writeHeader": "寫入",
			"mssql.executeHeader": "執行",
			"mssql.addUserOrGroup": "新增使用者或群組",
			"mssql.enterNamePlaceholder": "輸入名稱",
			"mssql.addLabel": "新增",
			"mssql.namedUsersAndGroups": "具名使用者和群組",
			"mssql.apply": "套用",
			"mssql.applyRecursively": "遞迴套用",
			"mssql.errorApplyingAclChanges": "套用變更時發生未預期的錯誤: {0}",
			"sparkJobSubmission_LocalFileDestinationHint": "本機檔案將上傳至 HDFS。",
			"sparkJobSubmission_SubmissionEndMessage": ".......................... 提交 Spark 作業結束 ............................",
			"sparkJobSubmission_PrepareUploadingFile": "正在從本機 {0} 將檔案上傳至 HDFS 資料夾: {1}",
			"sparkJobSubmission_UploadingFileSucceeded": "已成功將檔案上傳至叢集!",
			"sparkJobSubmission_UploadingFileFailed": "無法將檔案上傳至叢集。{0}",
			"sparkJobSubmission_PrepareSubmitJob": "正在提交作業 {0} ...",
			"sparkJobSubmission_SubmitJobFinished": "已提交 Spark 作業。",
			"sparkJobSubmission_SubmitJobFailed": "Spark 作業提交失敗。{0}",
			"sparkJobSubmission_YarnUIMessage": "YarnUI Url: {0}",
			"sparkJobSubmission_SparkHistoryLinkMessage": "Spark 歷程記錄 Url: {0}",
			"sparkJobSubmission_GetApplicationIdFailed": "無法取得應用程式識別碼。{0}",
			"sparkJobSubmission_LocalFileNotExisted": "本機檔案 {0} 不存在。",
			"sparkJobSubmission_NoSqlBigDataClusterFound": "找不到任何 SQL Server 巨量資料叢集。"
		},
		"dist/objectExplorerNodeProvider/fileSources": {
			"maxSizeNotice": "注意: 此檔案已於 {0} 截斷，以供預覽。",
			"maxSizeReached": "檔案已於 {0} 截斷，以供預覽。"
		},
		"dist/objectExplorerNodeProvider/command": {
			"progress": "$(sync~spin) {0}...",
			"cancelTooltip": "取消",
			"cancel": "要取消作業嗎?",
			"mssql.searchServers": "搜尋伺服器名稱"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionService": {
			"sparkJobSubmission_LivyNoBatchIdReturned": "回應未傳回任何 Spark 作業批次識別碼。{0}[錯誤] {1}",
			"sparkJobSubmission_LivyNoLogReturned": "回應中未傳回任何記錄。{0}[錯誤] {1}"
		},
		"dist/objectExplorerNodeProvider/hdfsCommands": {
			"allFiles": "所有檔案",
			"lblUploadFiles": "上傳",
			"uploading": "正在將檔案上傳至 HDFS",
			"uploadCanceled": "上傳作業已取消",
			"uploadError": "上傳檔案時發生錯誤: {0}",
			"makingDir": "正在建立目錄",
			"mkdirCanceled": "作業已取消",
			"mkDirError": "製作目錄時發生錯誤: {0}",
			"enterDirName": "輸入目錄名稱",
			"deleteError": "刪除檔案時發生錯誤: {0}",
			"msgDeleteFolder": "確定要刪除此資料夾和其內容嗎?",
			"msgDeleteFile": "確定要刪除此檔案嗎?",
			"saving": "正在儲存 HDFS 檔案",
			"saveCanceled": "儲存作業已取消",
			"saveError": "儲存檔案時發生錯誤: {0}",
			"previewing": "正在產生預覽",
			"previewError": "預覽檔案時發生錯誤: {0}",
			"copyPathError": "複製路徑時發生錯誤: {0}",
			"manageAccessError": "開啟管理存取權對話方塊時發生未預期的錯誤: {0}"
		},
		"dist/hdfs/webhdfs": {
			"webhdfs.invalidDataStructure": "資料結構無效",
			"webhdfs.missingProperties": "因為缺少選項，所以無法建立 WebHDFS 用戶端: ${0}",
			"webhdfs.undefinedArgument": "'${0}' 未定義。",
			"webhdfs.httpError400": "不正確的要求",
			"webhdfs.httpError401": "未經授權",
			"webhdfs.httpError403": "禁止",
			"webhdfs.httpError404": "找不到",
			"webhdfs.httpError500": "內部伺服器錯誤",
			"webhdfs.unknownError": "未知的錯誤",
			"webhdfs.unexpectedRedirect": "未預期的重新導向"
		},
		"dist/objectExplorerNodeProvider/connection": {
			"connectionInfoUndefined": "未定義 ConnectionInfo。",
			"connectionInfoOptionsUndefined": "未定義 ConnectionInfo.options。",
			"connectionInfoOptionsMissingProperties": "connectionInfo.options 中遺失的部分屬性: {0}"
		},
		"dist/telemetry": {
			"viewKnownIssuesText": "檢視已知問題",
			"serviceCrashMessage": "{0} 個元件意外結束。請重新啟動 Azure Data Studio。"
		},
		"dist/main": {
			"msgSampleCodeDataFrame": "這個範例程式碼會將檔案載入資料框架，並顯示前 10 個結果。",
			"notebookFileType": "Notebooks",
			"unsupportedFileType": "僅支援 .ipynb Notebooks",
			"fileNotFound": "找不到指定的檔案"
		},
		"dist/hdfs/hdfsModel": {
			"mssql.recursivePermissionOpStarted": "正在 ‘{0}’ 下遞迴套用權限變更",
			"mssql.recursivePermissionOpSucceeded": "已成功套用權限變更。",
			"mssql.recursivePermissionOpProgress": "將權限變更套用到 ‘{0}’",
			"mssql.recursivePermissionOpError": "套用權限變更時發生錯誤: {0}"
		},
		"dist/prompts/confirm": {
			"msgYes": "是",
			"msgNo": "否"
		},
		"dist/sparkFeature/dialog/dialogCommands": {
			"selectOtherServer": "選取其他 SQL Server",
			"sparkJobSubmission_PleaseSelectSqlWithCluster": "請選取具有巨量資料叢集的 SQL Server。",
			"sparkJobSubmission_NoSqlSelected": "未選取任何 SQL Server。",
			"errorNotSqlBigDataCluster": "所選伺服器不屬於 SQL Server 巨量資料叢集",
			"sparkJobSubmission_GetFilePathFromSelectedNodeFailed": "取得檔案路徑時發生錯誤: {0}"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionDialog": {
			"sparkJobSubmission_SparkJobSubmissionDialogInitializeError": "SparkJobSubmissionDialog 的參數不合法",
			"sparkJobSubmission_DialogTitleNewJob": "新增作業",
			"sparkJobSubmission_DialogCancelButton": "取消",
			"sparkJobSubmission_DialogSubmitButton": "提交",
			"sparkJobSubmission_SubmitSparkJob": "{0} Spark 作業提交:",
			"sparkJobSubmission_SubmissionStartMessage": ".......................... 提交 Spark 作業開始 .........................."
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionModel": {
			"sparkJobSubmission_SparkJobSubmissionModelInitializeError": "SparkJobSubmissionModel 的參數不合法",
			"sparkJobSubmission_submissionArgsIsInvalid": "submissionArgs 無效。",
			"sparkJobSubmission_LivyBatchIdIsInvalid": "livyBatchId 無效。",
			"sparkJobSubmission_GetApplicationIdTimeOut": "取得應用程式識別碼逾時。{0}[記錄]   {1}",
			"sparkJobSubmission_localFileOrFolderNotSpecified.": "未指定屬性 localFilePath 或 hdfsFolderPath。",
			"sparkJobSubmission_PathNotSpecified.": "未指定屬性路徑。"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkConfigurationTab": {
			"sparkJobSubmission_GeneralTabName": "一般",
			"sparkJobSubmission_JobNamePlaceHolder": "請輸入名稱...",
			"sparkJobSubmission_JobName": "作業名稱",
			"sparkJobSubmission_SparkCluster": "Spark 叢集",
			"sparkJobSubmission_FilePathPlaceHolder": ".jar 或 .py 檔案的路徑",
			"sparkJobSubmission_LocalFileDestinationHintWithPath": "選取的本機檔案將會上傳至 HDFS: {0}",
			"sparkJobSubmission_MainFilePath": "JAR/py 檔案",
			"sparkJobSubmission_MainClass": "主要類別",
			"sparkJobSubmission_Arguments": "引數",
			"sparkJobSubmission_ArgumentsTooltip": "在您主要類別中使用的命令列引數，多個引數應以空格分隔。",
			"sparkJobSubmission_NotSpecifyJobName": "未指定屬性作業名稱。",
			"sparkJobSubmission_NotSpecifyJARPYPath": "未指定屬性 JAR/py 檔案。",
			"sparkJobSubmission_NotSpecifyMainClass": "未指定屬性主要類別。",
			"sparkJobSubmission_HDFSFileNotExistedWithPath": "{0} 不存在於叢集或擲回例外狀況中。",
			"sparkJobSubmission_HDFSFileNotExisted": "指定的 HDFS 檔案不存在。",
			"sparkSelectLocalFile": "選擇",
			"sparkJobSubmission_SelectFileError": "因為發生錯誤，所以在尋找檔案時發生錯誤: {0}"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkAdvancedTab": {
			"sparkJobSubmission_AdvancedTabName": "進階",
			"sparkJobSubmission_ReferenceJarList": "參考 Jars",
			"sparkJobSubmission_ReferenceJarListToolTip": "要放置在執行程式工作目錄中的 Jar。Jar 路徑必須為 HDFS 路徑。多個路徑應以分號 (;) 分隔",
			"sparkJobSubmission_ReferencePyList": "參考 py 檔案",
			"sparkJobSubmission_ReferencePyListTooltip": "要放置於執行程式工作目錄的 Py 檔案。檔案路徑必須為 HDFS 路徑。多個路徑應以分號 (;) 分隔",
			"sparkJobSubmission_ReferenceFilesList": "參考檔案",
			"sparkJobSubmission_ReferenceFilesListTooltip": "要放置於執行程式工作目錄的檔案。檔案路徑必須為 HDFS 路徑。多個路徑應以分號 (;) 分隔"
		},
		"dist/objectExplorerNodeProvider/objectExplorerNodeProvider": {
			"prmptPwd": "請提供連線至 HDFS 的密碼:",
			"sessionNotFound": "節點 {0} 的工作階段不存在",
			"notifyError": "通知節點變更時發生錯誤: {0}",
			"hdfsFolder": "HDFS",
			"rootLabel": "根"
		},
		"dist/objectExplorerNodeProvider/hdfsProvider": {
			"errorExpanding": "錯誤: {0}",
			"errDeleteConnectionNode": "無法刪除連線。只能刪除子資料夾和檔案。"
		},
		"dist/objectExplorerNodeProvider/cancelableStream": {
			"streamCanceled": "使用者取消了串流作業"
		},
		"dist/dashboard/serviceEndpoints": {
			"grafana": "計量儀表板",
			"kibana": "記錄搜尋儀表板",
			"sparkHistory": "Spark 作業管理與監視儀表板",
			"yarnHistory": "Spark 診斷與監視儀表板",
			"copyText": "複製",
			"endpoint.appproxy": "應用程式 Proxy",
			"endpoint.controller": "叢集管理服務",
			"endpoint.gateway": "用來存取 HDFS 檔案的閘道，Spark",
			"endpoint.managementproxy": "管理 Proxy",
			"endpoint.mgmtproxy": "管理 Proxy",
			"endpoint.sqlServerEndpoint": "SQL Server 主要執行個體前端",
			"endpoint.grafana": "計量儀表板",
			"endpoint.kibana": "記錄搜尋儀表板",
			"endpoint.yarnHistory": "Spark 診斷與監視儀表板",
			"endpoint.sparkHistory": "Spark 作業管理與監視儀表板",
			"endpoint.webhdfs": "HDFS 檔案系統 Proxy",
			"endpoint.livy": "用來執行 Spark 陳述式、作業、應用程式的 Proxy"
		},
		"dist/sqlToolsServer": {
			"serviceStartedStatusMsg": "已啟動 {0}",
			"startingServiceStatusMsg": "正在啟動 {0}",
			"failedToStartServiceErrorMsg": "無法啟動 {0}",
			"installingServiceChannelMsg": "正在將 {0} 安裝到 {1}",
			"installingServiceStatusMsg": "正在安裝 {0}",
			"installedServiceChannelMsg": "已安裝 {0}",
			"downloadingServiceChannelMsg": "正在下載 {0}",
			"downloadingServiceSizeChannelMsg": "({0} KB)",
			"downloadingServiceStatusMsg": "正在下載 {0}",
			"downloadServiceDoneChannelMsg": "已完成 {0} 的安裝"
		}
	}
}