{
	"": [
		"--------------------------------------------------------------------------------------------",
		"Copyright (c) Microsoft Corporation. All rights reserved.",
		"Licensed under the Source EULA. See License.txt in the project root for license information.",
		"--------------------------------------------------------------------------------------------",
		"Do not edit this file. It is machine generated."
	],
	"version": "1.0.0",
	"contents": {
		"package": {
			"json.schemas.desc": "Связь схем с JSON-файлами в текущем проекте",
			"json.schemas.url.desc": "URL-адрес схемы или относительный путь к ней в текущем каталоге",
			"json.schemas.fileMatch.desc": "Массив шаблонов файлов, с которым выполняется сравнение, при разрешении JSON-файлов в схемах.",
			"json.schemas.fileMatch.item.desc": "Шаблон файла, который может содержать \"*\" и с которым выполняется сравнение, при разрешении JSON-файлов в схемах.",
			"json.schemas.schema.desc": "Определение схемы для указанного URL-адреса. Схему необходимо указать только для того, чтобы не обращаться по URL-адресу схемы.",
			"json.format.enable.desc": "Включение или отключение модуля форматирования JSON по умолчанию (требуется перезагрузка)",
			"mssqlCluster.uploadFiles": "Отправить файлы",
			"mssqlCluster.mkdir": "Создать каталог",
			"mssqlCluster.deleteFiles": "Удалить",
			"mssqlCluster.previewFile": "Предварительная версия",
			"mssqlCluster.saveFile": "Сохранить",
			"mssqlCluster.copyPath": "Скопировать путь",
			"mssqlCluster.manageAccess": "Управление доступом",
			"notebook.command.new": "Создать записную книжку",
			"notebook.command.open": "Открыть записную книжку",
			"tab.bigDataClusterDescription": "Задачи и сведения о вашем кластере больших данных SQL Server",
			"title.bigDataCluster": "Кластер больших данных SQL Server",
			"title.submitSparkJob": "Отправить задание Spark",
			"title.newSparkJob": "Создать задание Spark",
			"title.openSparkHistory": "Просмотреть журнал Spark",
			"title.openYarnHistory": "Просмотреть журнал YARN",
			"title.tasks": "Задачи",
			"title.installPackages": "Установка пакетов",
			"title.configurePython": "Настройка Python для Записных книжек",
			"title.searchServers": "Поиск: серверы",
			"title.clearSearchServerResult": "Поиск: очистить результаты поиска сервера",
			"title.endpoints": "Конечные точки службы",
			"title.books": "Записные книжки",
			"title.showLogFile": "Показать файл журнала",
			"mssql.configuration.title": "Конфигурация MSSQL",
			"mssql.query.displayBitAsNumber": "Нужно ли отображать столбцы BIT как числа (1 или 0)? Если задано значение FALSE, столбцы BIT будут отображаться как \"TRUE\" или \"FALSE\"",
			"mssql.format.alignColumnDefinitionsInColumns": "Должны ли определения столбцов быть выровнены?",
			"mssql.format.datatypeCasing": "Следует ли форматировать типы данных в верхнем регистре, нижнем регистре или оставить без форматирования (\"нет\")",
			"mssql.format.keywordCasing": "Следует ли форматировать ключевые слова в верхнем регистре, нижнем регистре или оставить без форматирования (\"нет\")",
			"mssql.format.placeCommasBeforeNextStatement": "Следует ли ставить запятые в начале каждой инструкции в списке, например \", mycolumn2\", а не в конце, например \"mycolumn1,\"",
			"mssql.format.placeSelectStatementReferencesOnNewLine": "Нужно ли разделять на отдельные строки ссылки на объекты в выбранных инструкциях? Например, для \"SELECT C1, C2 FROM T1\" как C1, так и C2 будут находиться на отдельных строках",
			"mssql.logDebugInfo": "[Необязательно] Выведите выходные данные отладки в консоль (Вид -> Вывод), а затем выберите подходящий выходной канал в раскрывающемся списке",
			"mssql.tracingLevel": "[Необязательно] Уровень ведения журнала для серверных служб. Azure Data Studio создает имя файла при каждом запуске, а если такой файл уже существует, записи журналов добавляются в него. Для очистки старых файлов журналов см. описание параметров logRetentionMinutes и logFilesRemovalLimit. Параметр tracingLevel по умолчанию регистрирует не слишком многое. Изменение детализации может привести к тому, что журналы будут занимать слишком много места. Ошибка включает критический уровень, предупреждение включает ошибку, информационный уровень включает предупреждение, а подробный уровень включает информационный уровень.",
			"mssql.logRetentionMinutes": "Срок хранения файлов журналов (в минутах) для серверных служб. По умолчанию задана 1 неделя.",
			"mssql.logFilesRemovalLimit": "Максимальное число старых файлов, удаляемых при запуске, с истекшим сроком mssql.logRetentionMinutes. Файлы, которые не были очищены из-за этого ограничения, очищаются при следующем запуске Azure Data Studio.",
			"ignorePlatformWarning": "[Необязательно] Не показывать предупреждения для неподдерживаемых платформ",
			"onprem.databaseProperties.recoveryModel": "Модель восстановления",
			"onprem.databaseProperties.lastBackupDate": "Последнее резервное копирование базы данных",
			"onprem.databaseProperties.lastLogBackupDate": "Последняя резервная копия журнала",
			"onprem.databaseProperties.compatibilityLevel": "Уровень совместимости",
			"onprem.databaseProperties.owner": "Владелец",
			"onprem.serverProperties.serverVersion": "Версия",
			"onprem.serverProperties.serverEdition": "Выпуск",
			"onprem.serverProperties.machineName": "Имя компьютера",
			"onprem.serverProperties.osVersion": "Версия ОС",
			"cloud.databaseProperties.azureEdition": "Выпуск",
			"cloud.databaseProperties.serviceLevelObjective": "Ценовая категория",
			"cloud.databaseProperties.compatibilityLevel": "Уровень совместимости",
			"cloud.databaseProperties.owner": "Владелец",
			"cloud.serverProperties.serverVersion": "Версия",
			"cloud.serverProperties.serverEdition": "Тип",
			"mssql.provider.displayName": "Microsoft SQL Server",
			"mssql.connectionOptions.connectionName.displayName": "Имя (необязательно)",
			"mssql.connectionOptions.connectionName.description": "Настраиваемое имя подключения",
			"mssql.connectionOptions.serverName.displayName": "Сервер",
			"mssql.connectionOptions.serverName.description": "Имя экземпляра SQL Server",
			"mssql.connectionOptions.databaseName.displayName": "База данных",
			"mssql.connectionOptions.databaseName.description": "Имя исходного каталога или базы данных в источнике данных",
			"mssql.connectionOptions.authType.displayName": "Тип проверки подлинности",
			"mssql.connectionOptions.authType.description": "Указывает способ проверки подлинности в SQL Server",
			"mssql.connectionOptions.authType.categoryValues.sqlLogin": "Имя входе SQL",
			"mssql.connectionOptions.authType.categoryValues.integrated": "Проверка подлинности Windows.",
			"mssql.connectionOptions.authType.categoryValues.azureMFA": "Azure Active Directory — универсальный с поддержкой MFA",
			"mssql.connectionOptions.userName.displayName": "Имя пользователя",
			"mssql.connectionOptions.userName.description": "Указывает идентификатор пользователя, который необходимо использовать для подключения к источнику данных",
			"mssql.connectionOptions.password.displayName": "Пароль",
			"mssql.connectionOptions.password.description": "Указывает пароль, который необходимо использовать для подключения к источнику данных",
			"mssql.connectionOptions.applicationIntent.displayName": "Намерение приложения",
			"mssql.connectionOptions.applicationIntent.description": "Объявляет тип рабочей нагрузки приложения при подключении к серверу",
			"mssql.connectionOptions.asynchronousProcessing.displayName": "Асинхронная обработка",
			"mssql.connectionOptions.asynchronousProcessing.description": "Когда задано значение TRUE, разрешено использовать асинхронные функции в поставщике данных .NET Framework",
			"mssql.connectionOptions.connectTimeout.displayName": "Истекло время ожидания подключения",
			"mssql.connectionOptions.connectTimeout.description": "Длительность (в секундах) ожидания при подключении к серверу, после чего попытка прекращается и выводится ошибка",
			"mssql.connectionOptions.currentLanguage.displayName": "Текущий язык",
			"mssql.connectionOptions.currentLanguage.description": "Имя записи языка SQL Server",
			"mssql.connectionOptions.columnEncryptionSetting.displayName": "Шифрование столбцов",
			"mssql.connectionOptions.columnEncryptionSetting.description": "Параметр шифрования столбца по умолчанию для всех команд подключения",
			"mssql.connectionOptions.encrypt.displayName": "Шифровать",
			"mssql.connectionOptions.encrypt.description": "Когда задано значение TRUE, SQL Server использует шифрование SSL для всех данных, передаваемых между клиентом и сервером, если на сервере установлен сертификат",
			"mssql.connectionOptions.persistSecurityInfo.displayName": "Сохранение сведений о безопасности",
			"mssql.connectionOptions.persistSecurityInfo.description": "Если задано значение FALSE, то секретные данные (например, пароль) не возвращаются в составе подключения",
			"mssql.connectionOptions.trustServerCertificate.displayName": "Доверять сертификату сервера",
			"mssql.connectionOptions.trustServerCertificate.description": "Когда задано значение TRUE (и encrypt=true), SQL Server использует шифрование SSL для всех данных, передаваемых между клиентом и сервером без проверки сертификата сервера",
			"mssql.connectionOptions.attachedDBFileName.displayName": "Имя вложенного файла базы данных",
			"mssql.connectionOptions.attachedDBFileName.description": "Имя первичного файла прикрепляемой базы данных, включая полный путь",
			"mssql.connectionOptions.contextConnection.displayName": "Контекстное подключение",
			"mssql.connectionOptions.contextConnection.description": "Если задано значение TRUE, указывает, что подключение должно быть произведено в контексте SQL Server. Доступно только при выполнении в процессе SQL Server.",
			"mssql.connectionOptions.port.displayName": "Порт",
			"mssql.connectionOptions.connectRetryCount.displayName": "Счетчик повторных попыток для подключения",
			"mssql.connectionOptions.connectRetryCount.description": "Число попыток восстановления подключения",
			"mssql.connectionOptions.connectRetryInterval.displayName": "Интервал повторных попыток подключения",
			"mssql.connectionOptions.connectRetryInterval.description": "Задержка между попытками восстановления подключения",
			"mssql.connectionOptions.applicationName.displayName": "Имя приложения",
			"mssql.connectionOptions.applicationName.description": "Имя приложения",
			"mssql.connectionOptions.workstationId.displayName": "Идентификатор рабочей станции",
			"mssql.connectionOptions.workstationId.description": "Имя рабочей станции, подключающейся к SQL Server",
			"mssql.connectionOptions.pooling.displayName": "Объединение в пул",
			"mssql.connectionOptions.pooling.description": "Если задано значение TRUE, объект соединения извлекается из соответствующего пула или при необходимости создается и добавляется в соответствующий пул",
			"mssql.connectionOptions.maxPoolSize.displayName": "Максимальный размер пула",
			"mssql.connectionOptions.maxPoolSize.description": "Максимально допустимое число подключений в пуле",
			"mssql.connectionOptions.minPoolSize.displayName": "Минимальный размер пула",
			"mssql.connectionOptions.minPoolSize.description": "Минимально допустимое число подключений в пуле",
			"mssql.connectionOptions.loadBalanceTimeout.displayName": "Истекло время ожидания при балансировке нагрузки",
			"mssql.connectionOptions.loadBalanceTimeout.description": "Минимальное время (в секундах), которое это подключение будет оставаться в пуле до уничтожения",
			"mssql.connectionOptions.replication.displayName": "Репликация",
			"mssql.connectionOptions.replication.description": "Используется SQL Server при репликации",
			"mssql.connectionOptions.attachDbFilename.displayName": "Имя вложенного файла базы данных",
			"mssql.connectionOptions.failoverPartner.displayName": "Партнер по обеспечению отработки отказа",
			"mssql.connectionOptions.failoverPartner.description": "Имя или сетевой адрес экземпляра SQL Server, выступающего в роли партнера по обеспечению отработки отказа",
			"mssql.connectionOptions.multiSubnetFailover.displayName": "Отработка отказа в нескольких подсетях",
			"mssql.connectionOptions.multipleActiveResultSets.displayName": "Множественные активные результирующие наборы",
			"mssql.connectionOptions.multipleActiveResultSets.description": "Если задано значение TRUE, из одного подключения может быть возвращено и считано несколько результирующих наборов",
			"mssql.connectionOptions.packetSize.displayName": "Размер пакета",
			"mssql.connectionOptions.packetSize.description": "Размер (в байтах) сетевых пакетов, которые используются для взаимодействия с экземпляром SQL Server",
			"mssql.connectionOptions.typeSystemVersion.displayName": "Версия системы типов",
			"mssql.connectionOptions.typeSystemVersion.description": "Указывает, какую систему серверного типа предоставит поставщик через DataReader"
		},
		"dist/localizedConstants": {
			"msgMissingNodeContext": "Команда Node вызвана без передачи какого-либо узла",
			"mssql.manageAccessTitle": "Управление доступом",
			"mssql.locationTitle": "Расположение: ",
			"mssql.permissionsTitle": "Разрешения",
			"mssql.ownerPostfix": " — Владелец",
			"mssql.owningGroupPostfix": " — Группа-владелец",
			"mssql.everyone": "Все остальные",
			"mssql.userLabel": "Пользователь",
			"mssql.groupLabel": "Группа",
			"mssql.accessHeader": "Доступ",
			"mssql.defaultHeader": "По умолчанию",
			"mssql.delete": "Удалить",
			"mssql.stickyHeader": "Записка",
			"mssql.inheritDefaultsLabel": "Унаследовать значения по умолчанию",
			"mssql.readHeader": "Чтение",
			"mssql.writeHeader": "Запись",
			"mssql.executeHeader": "Выполнение",
			"mssql.addUserOrGroup": "Добавление пользователя или группы",
			"mssql.enterNamePlaceholder": "Введите имя",
			"mssql.addLabel": "Добавить",
			"mssql.namedUsersAndGroups": "Именованные пользователи и группы",
			"mssql.apply": "Применить",
			"mssql.applyRecursively": "Применить рекурсивно",
			"mssql.errorApplyingAclChanges": "Непредвиденная ошибка при применении изменений: {0}",
			"sparkJobSubmission_LocalFileDestinationHint": "Локальный файл будет отправлен в HDFS.",
			"sparkJobSubmission_SubmissionEndMessage": ".......................... Конец отправки задания Spark ............................",
			"sparkJobSubmission_PrepareUploadingFile": "Отправка файла из локального {0} в папку HDFS: {1}",
			"sparkJobSubmission_UploadingFileSucceeded": "Отправка файла в кластер успешно завершена.",
			"sparkJobSubmission_UploadingFileFailed": "Отправка файла в кластер завершилась сбоем. {0}",
			"sparkJobSubmission_PrepareSubmitJob": "Отправка задания {0}…",
			"sparkJobSubmission_SubmitJobFinished": "Задание Spark было отправлено.",
			"sparkJobSubmission_SubmitJobFailed": "Сбой при отправке задания Spark. {0}",
			"sparkJobSubmission_YarnUIMessage": "URL-адрес YarnUI: {0}",
			"sparkJobSubmission_SparkHistoryLinkMessage": "URL-адрес журнала Spark: {0}",
			"sparkJobSubmission_GetApplicationIdFailed": "Сбой при получении идентификатора приложения. {0}",
			"sparkJobSubmission_LocalFileNotExisted": "Локальный файл {0} не существует.",
			"sparkJobSubmission_NoSqlBigDataClusterFound": "Кластер больших данных SQL Server не найден."
		},
		"dist/objectExplorerNodeProvider/fileSources": {
			"maxSizeNotice": "Уведомление. Этот файл был обрезан на {0} для предварительного просмотра.",
			"maxSizeReached": "Файл был обрезан на {0} для предварительного просмотра."
		},
		"dist/objectExplorerNodeProvider/command": {
			"progress": "$(sync~spin) {0}…",
			"cancelTooltip": "Отмена",
			"cancel": "Отменить операцию?",
			"mssql.searchServers": "Поиск имен серверов"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionService": {
			"sparkJobSubmission_LivyNoBatchIdReturned": "Идентификатор пакета задания Spark не возвращен из ответа.{0}[Ошибка] {1}",
			"sparkJobSubmission_LivyNoLogReturned": "Журнал не возвращен в ответе.{0}[Ошибка] {1}"
		},
		"dist/objectExplorerNodeProvider/hdfsCommands": {
			"allFiles": "Все файлы",
			"lblUploadFiles": "Передать",
			"uploading": "Идет отправка файлов в HDFS",
			"uploadCanceled": "Операция отправки была отменена",
			"uploadError": "Ошибка при отправке файлов: {0}",
			"makingDir": "Идет создание каталога",
			"mkdirCanceled": "Операция отменена",
			"mkDirError": "Ошибка при создании каталога: {0}",
			"enterDirName": "Введите имя каталога",
			"deleteError": "Ошибка при удалении файлов: {0}",
			"msgDeleteFolder": "Вы действительно хотите удалить эту папку и ее содержимое?",
			"msgDeleteFile": "Вы действительно хотите удалить этот файл?",
			"saving": "Идет сохранение файлов HDFS",
			"saveCanceled": "Операция сохранения была отменена",
			"saveError": "Ошибка при сохранении файла: {0}",
			"previewing": "Подготовка к предварительному просмотру",
			"previewError": "Ошибка при предварительном просмотре файла: {0}",
			"copyPathError": "Ошибка в пути копирования: {0}",
			"manageAccessError": "Непредвиденная ошибка при открытии диалогового окна \"Управление доступом\": {0}"
		},
		"dist/hdfs/webhdfs": {
			"webhdfs.invalidDataStructure": "Недопустимая структура данных",
			"webhdfs.missingProperties": "Не удалось создать клиент WebHDFS из-за отсутствующих параметров: ${0}",
			"webhdfs.undefinedArgument": "\"${0}\" не определен.",
			"webhdfs.httpError400": "Неправильный запрос",
			"webhdfs.httpError401": "Не авторизовано",
			"webhdfs.httpError403": "Запрещено",
			"webhdfs.httpError404": "Не найден",
			"webhdfs.httpError500": "Внутренняя ошибка сервера",
			"webhdfs.unknownError": "Неизвестная ошибка",
			"webhdfs.unexpectedRedirect": "Неожиданное перенаправление"
		},
		"dist/objectExplorerNodeProvider/connection": {
			"connectionInfoUndefined": "Параметр ConnectionInfo не определен.",
			"connectionInfoOptionsUndefined": "Параметр ConnectionInfo.options не определен.",
			"connectionInfoOptionsMissingProperties": "Отсутствуют некоторые свойства в параметре connectionInfo.options: {0}"
		},
		"dist/telemetry": {
			"viewKnownIssuesText": "Просмотреть известные проблемы",
			"serviceCrashMessage": "Компонент {0} неожиданно завершил работу. Перезапустите Azure Data Studio."
		},
		"dist/main": {
			"msgSampleCodeDataFrame": "Этот пример кода загружает файл в кадр данных и отображает первые 10 результатов.",
			"notebookFileType": "Записные книжки",
			"unsupportedFileType": "Поддерживаются только записные книжки IPYNB",
			"fileNotFound": "Не удалось найти указанный файл"
		},
		"dist/hdfs/hdfsModel": {
			"mssql.recursivePermissionOpStarted": "Рекурсивное применение изменений разрешений в \"{0}\"",
			"mssql.recursivePermissionOpSucceeded": "Изменения разрешений применены.",
			"mssql.recursivePermissionOpProgress": "Применение изменений разрешений к \"{0}\".",
			"mssql.recursivePermissionOpError": "Ошибка при применении изменений разрешений: {0}"
		},
		"dist/prompts/confirm": {
			"msgYes": "Да",
			"msgNo": "Нет"
		},
		"dist/sparkFeature/dialog/dialogCommands": {
			"selectOtherServer": "Выберите другой сервер SQL Server",
			"sparkJobSubmission_PleaseSelectSqlWithCluster": "Выберите сервер SQL Server с кластером больших данных.",
			"sparkJobSubmission_NoSqlSelected": "Сервер SQL Server не выбран.",
			"errorNotSqlBigDataCluster": "Выбранный сервер не относится к кластеру больших данных SQL Server",
			"sparkJobSubmission_GetFilePathFromSelectedNodeFailed": "Ошибка при получении пути к файлу: {0}"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionDialog": {
			"sparkJobSubmission_SparkJobSubmissionDialogInitializeError": "Недопустимые параметры для SparkJobSubmissionDialog",
			"sparkJobSubmission_DialogTitleNewJob": "Новое задание",
			"sparkJobSubmission_DialogCancelButton": "Отмена",
			"sparkJobSubmission_DialogSubmitButton": "Отправить",
			"sparkJobSubmission_SubmitSparkJob": "Отправка задания Spark {0}:",
			"sparkJobSubmission_SubmissionStartMessage": "…………………….. Начало отправки задания Spark …………………….."
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionModel": {
			"sparkJobSubmission_SparkJobSubmissionModelInitializeError": "Недопустимые параметры для SparkJobSubmissionModel",
			"sparkJobSubmission_submissionArgsIsInvalid": "Недопустимый submissionArgs.",
			"sparkJobSubmission_LivyBatchIdIsInvalid": "Недопустимый livyBatchId.",
			"sparkJobSubmission_GetApplicationIdTimeOut": "Истекло время ожидания при получении идентификатора приложения. {0}[Журнал]   {1}",
			"sparkJobSubmission_localFileOrFolderNotSpecified.": "Не указано свойство localFilePath или hdfsFolderPath.",
			"sparkJobSubmission_PathNotSpecified.": "Путь к свойству не указан."
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkConfigurationTab": {
			"sparkJobSubmission_GeneralTabName": "Общее",
			"sparkJobSubmission_JobNamePlaceHolder": "Введите имя…",
			"sparkJobSubmission_JobName": "Имя задания",
			"sparkJobSubmission_SparkCluster": "Кластер Spark",
			"sparkJobSubmission_FilePathPlaceHolder": "Путь к файлу JAR или PY",
			"sparkJobSubmission_LocalFileDestinationHintWithPath": "Выбранный локальный файл будет отправлен в HDFS: {0}",
			"sparkJobSubmission_MainFilePath": "Файл JAR/py",
			"sparkJobSubmission_MainClass": "Класс Main",
			"sparkJobSubmission_Arguments": "Аргументы",
			"sparkJobSubmission_ArgumentsTooltip": "Аргументы командной строки, используемые в классе main; несколько аргументов следует разделять пробелом.",
			"sparkJobSubmission_NotSpecifyJobName": "Имя задания свойства не указано.",
			"sparkJobSubmission_NotSpecifyJARPYPath": "Не указан файл свойств JAR/PY.",
			"sparkJobSubmission_NotSpecifyMainClass": "Не указан класс свойств Main.",
			"sparkJobSubmission_HDFSFileNotExistedWithPath": "{0} не существует в кластере, или возникло исключение.",
			"sparkJobSubmission_HDFSFileNotExisted": "Указанный файл HDFS не существует. ",
			"sparkSelectLocalFile": "Выбрать",
			"sparkJobSubmission_SelectFileError": "Не удалось обнаружить файл из-за ошибки: {0}"
		},
		"dist/sparkFeature/dialog/sparkJobSubmission/sparkAdvancedTab": {
			"sparkJobSubmission_AdvancedTabName": "Дополнительный",
			"sparkJobSubmission_ReferenceJarList": "Ссылки на JAR-файлы",
			"sparkJobSubmission_ReferenceJarListToolTip": "JAR-файлы, помещаемые в рабочий каталог исполнителя. Путь к JAR-файлу должен быть путем HDFS. Несколько путей следует разделять точкой с запятой (;)",
			"sparkJobSubmission_ReferencePyList": "PY-файлы ссылок",
			"sparkJobSubmission_ReferencePyListTooltip": "Файлы PY, помещаемые в рабочий каталог исполнителя. Путь к файлу должен быть путем HDFS. Несколько путей следует разделять точкой с запятой (;)",
			"sparkJobSubmission_ReferenceFilesList": "Файлы ссылок",
			"sparkJobSubmission_ReferenceFilesListTooltip": "Файлы, помещаемые в рабочий каталог исполнителя. Путь к файлу должен быть путем HDFS. Несколько путей следует разделять точкой с запятой (;)"
		},
		"dist/objectExplorerNodeProvider/objectExplorerNodeProvider": {
			"prmptPwd": "Укажите пароль для подключения HDFS:",
			"sessionNotFound": "Сеанс для узла {0} не существует",
			"notifyError": "Ошибка при уведомлении об изменении узла: {0}",
			"hdfsFolder": "HDFS",
			"rootLabel": "Корень"
		},
		"dist/objectExplorerNodeProvider/hdfsProvider": {
			"errorExpanding": "Ошибка: {0}",
			"errDeleteConnectionNode": "Не удается удалить подключение. Можно удалить только вложенные папки и файлы."
		},
		"dist/objectExplorerNodeProvider/cancelableStream": {
			"streamCanceled": "Потоковая операция отменена пользователем"
		},
		"dist/dashboard/serviceEndpoints": {
			"grafana": "Панель мониторинга метрик",
			"kibana": "Панель мониторинга поиска по журналам",
			"sparkHistory": "Панель мониторинга для отслеживания заданий Spark и управления ими",
			"yarnHistory": "Панель мониторинга для отслеживания и диагностики Spark",
			"copyText": "Копировать",
			"endpoint.appproxy": "Прокси приложения",
			"endpoint.controller": "Служба управления кластерами",
			"endpoint.gateway": "Шлюз для доступа к файлам HDFS, Spark",
			"endpoint.managementproxy": "Прокси-сервер управления",
			"endpoint.mgmtproxy": "Прокси-сервер управления",
			"endpoint.sqlServerEndpoint": "Интерфейс главного экземпляра SQL Server",
			"endpoint.grafana": "Панель мониторинга метрик",
			"endpoint.kibana": "Панель мониторинга поиска по журналам",
			"endpoint.yarnHistory": "Панель мониторинга для отслеживания и диагностики Spark",
			"endpoint.sparkHistory": "Панель мониторинга для отслеживания заданий Spark и управления ими",
			"endpoint.webhdfs": "Прокси-сервер файловой системы HDFS",
			"endpoint.livy": "Прокси-сервер для выполнения инструкций, заданий и приложений Spark"
		},
		"dist/sqlToolsServer": {
			"serviceStartedStatusMsg": "{0} запущен",
			"startingServiceStatusMsg": "Запуск (0)",
			"failedToStartServiceErrorMsg": "Не удалось запустить {0}",
			"installingServiceChannelMsg": "Установка {0} в {1}",
			"installingServiceStatusMsg": "Установка (0)",
			"installedServiceChannelMsg": "Установлено: {0}",
			"downloadingServiceChannelMsg": "Идет загрузка {0}",
			"downloadingServiceSizeChannelMsg": "({0} КБ)",
			"downloadingServiceStatusMsg": "Идет загрузка {0}",
			"downloadServiceDoneChannelMsg": "Выполнена установка {0}"
		}
	}
}